{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 암환자 유전체 데이터 기반 암종 분류 AI 모델 개발\n",
    "\n",
    "\n",
    "- '2024 생명연구자원 AI활용 경진대회'는 바이오 데이터를 기반으로 한 AI 기술의 문제 해결 능력을 탐구하는 것을 목표로 합니다. <br>이 대회는 바이오 분야에서 AI 활용의 저변을 확대하고, 복잡한 바이오 데이터를 효율적으로 분석 및 해석할 수 있는 AI 알고리즘 개발에 초점을 맞추고 있습니다. <br><br>\n",
    "- 본 대회의 구체적인 과제는 암환자 유전체 데이터의 변이 정보를 활용하여 암종을 분류하는 AI 모델을 개발하는 것입니다. <br>참가자들은 제공된 학습 데이터셋(암환자 유전체 변이 정보)을 사용하여 특정 변이 정보를 바탕으로 암종을 정확하게 분류할 수 있는 AI 알고리즘을 개발해야 합니다. <br><br>\n",
    "- 이 대회의 궁극적인 목적은 바이오 데이터의 활용도를 높이고, 바이오 분야에서 AI 기술의 적용 가능성을 극대화하며, 인공지능 기술이 실제 바이오 의료 문제 해결에 어떻게 기여할 수 있는지 탐구하는 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "# import xgboost as xgb\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 표준화 - 표준화된 데이터르 svc 적용하는데.. 커널별로 적용\n",
    "# 이러한 과정을 파이프라인에 넣어서 한번에 처리한다.\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./train.csv\")\n",
    "test = pd.read_csv(\"./test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.head()\n",
    "# train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원래 레이블: ACC, 변환된 숫자: 0\n",
      "원래 레이블: BLCA, 변환된 숫자: 1\n",
      "원래 레이블: BRCA, 변환된 숫자: 2\n",
      "원래 레이블: CESC, 변환된 숫자: 3\n",
      "원래 레이블: COAD, 변환된 숫자: 4\n",
      "원래 레이블: DLBC, 변환된 숫자: 5\n",
      "원래 레이블: GBMLGG, 변환된 숫자: 6\n",
      "원래 레이블: HNSC, 변환된 숫자: 7\n",
      "원래 레이블: KIPAN, 변환된 숫자: 8\n",
      "원래 레이블: KIRC, 변환된 숫자: 9\n",
      "원래 레이블: LAML, 변환된 숫자: 10\n",
      "원래 레이블: LGG, 변환된 숫자: 11\n",
      "원래 레이블: LIHC, 변환된 숫자: 12\n",
      "원래 레이블: LUAD, 변환된 숫자: 13\n",
      "원래 레이블: LUSC, 변환된 숫자: 14\n",
      "원래 레이블: OV, 변환된 숫자: 15\n",
      "원래 레이블: PAAD, 변환된 숫자: 16\n",
      "원래 레이블: PCPG, 변환된 숫자: 17\n",
      "원래 레이블: PRAD, 변환된 숫자: 18\n",
      "원래 레이블: SARC, 변환된 숫자: 19\n",
      "원래 레이블: SKCM, 변환된 숫자: 20\n",
      "원래 레이블: STES, 변환된 숫자: 21\n",
      "원래 레이블: TGCT, 변환된 숫자: 22\n",
      "원래 레이블: THCA, 변환된 숫자: 23\n",
      "원래 레이블: THYM, 변환된 숫자: 24\n",
      "원래 레이블: UCEC, 변환된 숫자: 25\n"
     ]
    }
   ],
   "source": [
    "# SUBCLASS 가 범주형이기 때문에 LabelEncoder 사용\n",
    "le_subclass = LabelEncoder()\n",
    "train['SUBCLASS'] = le_subclass.fit_transform(train['SUBCLASS'])\n",
    "\n",
    "# 변환된 레이블 확인\n",
    "for i, label in enumerate(le_subclass.classes_):\n",
    "    print(f\"원래 레이블: {label}, 변환된 숫자: {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## x 의 경우도 범주형으로 구성되어 있어, 알맞은 인코딩 필요\n",
    "X = train.drop(columns=['SUBCLASS', 'ID'])\n",
    "y_subclass = train['SUBCLASS']\n",
    "\n",
    "categorical_columns = X.select_dtypes(include=['object', 'category']).columns\n",
    "ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "X_encoded = X.copy()\n",
    "X_encoded[categorical_columns] = ordinal_encoder.fit_transform(X[categorical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A2M</th>\n",
       "      <th>AAAS</th>\n",
       "      <th>AADAT</th>\n",
       "      <th>AARS1</th>\n",
       "      <th>ABAT</th>\n",
       "      <th>ABCA1</th>\n",
       "      <th>ABCA2</th>\n",
       "      <th>ABCA3</th>\n",
       "      <th>ABCA4</th>\n",
       "      <th>ABCA5</th>\n",
       "      <th>...</th>\n",
       "      <th>ZNF292</th>\n",
       "      <th>ZNF365</th>\n",
       "      <th>ZNF639</th>\n",
       "      <th>ZNF707</th>\n",
       "      <th>ZNFX1</th>\n",
       "      <th>ZNRF4</th>\n",
       "      <th>ZPBP</th>\n",
       "      <th>ZW10</th>\n",
       "      <th>ZWINT</th>\n",
       "      <th>ZYX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>137.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>161.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>137.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>161.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>161.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>137.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>161.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>161.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     A2M  AAAS  AADAT  AARS1  ABAT  ABCA1  ABCA2  ABCA3  ABCA4  ABCA5  ...  \\\n",
       "0  137.0  42.0   24.0    0.0  47.0  141.0  114.0  124.0  187.0  102.0  ...   \n",
       "1  137.0  42.0   24.0    0.0  47.0  141.0  114.0  124.0  187.0  102.0  ...   \n",
       "2  104.0  42.0   24.0    0.0  47.0  141.0  114.0  124.0  187.0  102.0  ...   \n",
       "3  137.0  42.0   24.0    0.0  47.0  141.0  114.0  124.0  187.0  102.0  ...   \n",
       "4  137.0  42.0   24.0    0.0  47.0  141.0  114.0  124.0  187.0  102.0  ...   \n",
       "\n",
       "   ZNF292  ZNF365  ZNF639  ZNF707  ZNFX1  ZNRF4  ZPBP  ZW10  ZWINT   ZYX  \n",
       "0   161.0    67.0    32.0    26.0  121.0   60.0  51.0  51.0   34.0  40.0  \n",
       "1   161.0    67.0    32.0    26.0  121.0   60.0  51.0  51.0   34.0  40.0  \n",
       "2   161.0    67.0    32.0    26.0  121.0   60.0  51.0  51.0   34.0  40.0  \n",
       "3   161.0    67.0    32.0    26.0  121.0   60.0  51.0  51.0   34.0  40.0  \n",
       "4   161.0    67.0    32.0    26.0  121.0   60.0  51.0  51.0   34.0  40.0  \n",
       "\n",
       "[5 rows x 4384 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_encoded 범주형 데이터는 순서가 있는 라벨링으로 변환한 학습용 데이터\n",
    "X_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Define and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = xgb.XGBClassifier(\n",
    "#     n_estimators=100,\n",
    "#     learning_rate=0.1,\n",
    "#     max_depth=6,\n",
    "#     random_state=42,\n",
    "#     use_label_encoder=False,\n",
    "#     eval_metric='mlogloss' \n",
    "# )\n",
    "\n",
    "# model = SVC()\n",
    "# SVC는 이진분류에 특화되어 있음\n",
    "# 다중분류는 OVR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가용 함수\n",
    "def print_score(clf, x_train,y_train,x_test,y_test, train=True):\n",
    "    if train:\n",
    "        pred = clf.predict(x_train)\n",
    "        clf_report = pd.DataFrame(classification_report(y_train,pred,output_dict=True))\n",
    "        print(\"Train Result : \\n ==============================================\")\n",
    "        print(f\"Accuracy score : {accuracy_score(y_train,pred)*100:.2f}%\")\n",
    "        print(\"---------------------------------------------------------------\")\n",
    "        print(f\"Calssfication Report:\\n{clf_report}\")\n",
    "        print('---------------------------------------------------------------')\n",
    "        print(f'Confusion Matrix: \\n{confusion_matrix(y_train,pred)}\\n')\n",
    "    else:\n",
    "        pred = clf.predict(x_test)\n",
    "        clf_report = pd.DataFrame(classification_report(y_test,pred,output_dict=True))\n",
    "        print(\"Test Result : \\n ==============================================\")\n",
    "        print(f\"Accuracy score : {accuracy_score(y_test,pred)*100:.2f}%\")\n",
    "        print(\"---------------------------------------------------------------\")\n",
    "        print(f\"Calssfication Report:\\n{clf_report}\")\n",
    "        print('---------------------------------------------------------------')\n",
    "        print(f'Confusion Matrix: \\n{confusion_matrix(y_test,pred)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train,x_test,y_train,y_test = train_test_split(X_encoded,y_subclass,stratify=y_subclass,random_state=42)\n",
    "\n",
    "# pipeline = Pipeline([\n",
    "#     ('std_scaler',StandardScaler()),\n",
    "#     ('logistic',LogisticRegression(max_iter=10000,C=0.01,penalty='l2',solver = \"newton-cg\" ))\n",
    "# ])\n",
    "# pipeline.fit(x_train,y_train)\n",
    "\n",
    "# # model = SVC()\n",
    "# # model = LogisticRegression(max_iter=10000)\n",
    "# # model.fit(X_encoded, y_subclass)\n",
    "\n",
    "# print_score(pipeline,x_train,y_train,x_test,y_test,train=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_score(pipeline,x_train,y_train,x_test,y_test,train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV] END logistic__C=0.1, logistic__max_iter=10000, logistic__penalty=l1, logistic__solver=newton-cg; total time=   0.8s\n",
      "[CV] END logistic__C=0.1, logistic__max_iter=10000, logistic__penalty=l1, logistic__solver=newton-cg; total time=   0.7s\n",
      "[CV] END logistic__C=0.1, logistic__max_iter=10000, logistic__penalty=l1, logistic__solver=newton-cg; total time=   0.7s\n",
      "[CV] END logistic__C=0.1, logistic__max_iter=10000, logistic__penalty=l1, logistic__solver=lbfgs; total time=   0.7s\n",
      "[CV] END logistic__C=0.1, logistic__max_iter=10000, logistic__penalty=l1, logistic__solver=lbfgs; total time=   0.8s\n",
      "[CV] END logistic__C=0.1, logistic__max_iter=10000, logistic__penalty=l1, logistic__solver=lbfgs; total time=   0.6s\n",
      "[CV] END logistic__C=0.1, logistic__max_iter=10000, logistic__penalty=l2, logistic__solver=newton-cg; total time=  26.9s\n",
      "[CV] END logistic__C=0.1, logistic__max_iter=10000, logistic__penalty=l2, logistic__solver=newton-cg; total time=  25.8s\n",
      "[CV] END logistic__C=0.1, logistic__max_iter=10000, logistic__penalty=l2, logistic__solver=newton-cg; total time=  27.3s\n",
      "[CV] END logistic__C=0.1, logistic__max_iter=10000, logistic__penalty=l2, logistic__solver=lbfgs; total time=   7.8s\n",
      "[CV] END logistic__C=0.1, logistic__max_iter=10000, logistic__penalty=l2, logistic__solver=lbfgs; total time=   8.2s\n",
      "[CV] END logistic__C=0.1, logistic__max_iter=10000, logistic__penalty=l2, logistic__solver=lbfgs; total time=   8.3s\n",
      "[CV] END logistic__C=10, logistic__max_iter=10000, logistic__penalty=l1, logistic__solver=newton-cg; total time=   0.6s\n",
      "[CV] END logistic__C=10, logistic__max_iter=10000, logistic__penalty=l1, logistic__solver=newton-cg; total time=   0.6s\n",
      "[CV] END logistic__C=10, logistic__max_iter=10000, logistic__penalty=l1, logistic__solver=newton-cg; total time=   0.7s\n",
      "[CV] END logistic__C=10, logistic__max_iter=10000, logistic__penalty=l1, logistic__solver=lbfgs; total time=   0.7s\n",
      "[CV] END logistic__C=10, logistic__max_iter=10000, logistic__penalty=l1, logistic__solver=lbfgs; total time=   0.7s\n",
      "[CV] END logistic__C=10, logistic__max_iter=10000, logistic__penalty=l1, logistic__solver=lbfgs; total time=   0.7s\n",
      "[CV] END logistic__C=10, logistic__max_iter=10000, logistic__penalty=l2, logistic__solver=newton-cg; total time=  48.0s\n",
      "[CV] END logistic__C=10, logistic__max_iter=10000, logistic__penalty=l2, logistic__solver=newton-cg; total time=  57.4s\n",
      "[CV] END logistic__C=10, logistic__max_iter=10000, logistic__penalty=l2, logistic__solver=newton-cg; total time= 1.3min\n",
      "[CV] END logistic__C=10, logistic__max_iter=10000, logistic__penalty=l2, logistic__solver=lbfgs; total time=  17.6s\n",
      "[CV] END logistic__C=10, logistic__max_iter=10000, logistic__penalty=l2, logistic__solver=lbfgs; total time=  17.9s\n",
      "[CV] END logistic__C=10, logistic__max_iter=10000, logistic__penalty=l2, logistic__solver=lbfgs; total time=  19.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\greatsangho\\AppData\\Local\\anaconda3\\envs\\mypjt001\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "12 fits failed out of a total of 24.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\greatsangho\\AppData\\Local\\anaconda3\\envs\\mypjt001\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\greatsangho\\AppData\\Local\\anaconda3\\envs\\mypjt001\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\greatsangho\\AppData\\Local\\anaconda3\\envs\\mypjt001\\Lib\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"C:\\Users\\greatsangho\\AppData\\Local\\anaconda3\\envs\\mypjt001\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\greatsangho\\AppData\\Local\\anaconda3\\envs\\mypjt001\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\greatsangho\\AppData\\Local\\anaconda3\\envs\\mypjt001\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\greatsangho\\AppData\\Local\\anaconda3\\envs\\mypjt001\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\greatsangho\\AppData\\Local\\anaconda3\\envs\\mypjt001\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\greatsangho\\AppData\\Local\\anaconda3\\envs\\mypjt001\\Lib\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"C:\\Users\\greatsangho\\AppData\\Local\\anaconda3\\envs\\mypjt001\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\greatsangho\\AppData\\Local\\anaconda3\\envs\\mypjt001\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\greatsangho\\AppData\\Local\\anaconda3\\envs\\mypjt001\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\greatsangho\\AppData\\Local\\anaconda3\\envs\\mypjt001\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.21483871 0.21462366        nan        nan\n",
      " 0.19096774 0.19311828]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters : {'logistic__C': 0.1, 'logistic__max_iter': 10000, 'logistic__penalty': 'l2', 'logistic__solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X_encoded,y_subclass,stratify=y_subclass,random_state=42)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('std_scaler',StandardScaler()),\n",
    "    ('logistic',LogisticRegression())\n",
    "])\n",
    "param_grid = {\n",
    "    'logistic__C' : [0.1, 10],\n",
    "    'logistic__penalty' : ['l1','l2'],\n",
    "    'logistic__max_iter' : [10000],\n",
    "    # 'logistic__class_weight' : ['balanced', None],\n",
    "    # 'logistic__multi_class' : ['auto', 'ovr', 'nultinomial'],\n",
    "    # 'logistic__tol' : [1e-4, 1e-3, 1e-2],\n",
    "    'logistic__solver' : ['newton-cg','lbfgs'] # 'saga'\n",
    "}\n",
    "\n",
    "gridcv = GridSearchCV(pipeline,param_grid=param_grid,cv=3,verbose=2)\n",
    "# 하이퍼 파라이터 적용\n",
    "gridcv.fit(x_train,y_train)\n",
    "print(f'best parameters : {gridcv.best_params_}')\n",
    "model = gridcv.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result : \n",
      " ==============================================\n",
      "Accuracy score : 92.65%\n",
      "---------------------------------------------------------------\n",
      "Calssfication Report:\n",
      "              0     1           2           3      4     5           6  \\\n",
      "precision   1.0   1.0    0.994845    1.000000    1.0   1.0    0.858790   \n",
      "recall      1.0   1.0    0.983022    0.991379    1.0   1.0    0.861272   \n",
      "f1-score    1.0   1.0    0.988898    0.995671    1.0   1.0    0.860029   \n",
      "support    54.0  78.0  589.000000  116.000000  167.0  29.0  346.000000   \n",
      "\n",
      "                    7           8           9  ...          19     20  \\\n",
      "precision    1.000000    0.791457    0.716814  ...    1.000000    1.0   \n",
      "recall       0.994012    0.816062    0.648000  ...    0.959459    1.0   \n",
      "f1-score     0.996997    0.803571    0.680672  ...    0.979310    1.0   \n",
      "support    167.000000  386.000000  250.000000  ...  148.000000  207.0   \n",
      "\n",
      "                   21         22         23         24     25  accuracy  \\\n",
      "precision    1.000000   1.000000    0.72973   1.000000    1.0  0.926452   \n",
      "recall       0.992958   0.989247    1.00000   0.621622    1.0  0.926452   \n",
      "f1-score     0.996466   0.994595    0.84375   0.766667    1.0  0.926452   \n",
      "support    284.000000  93.000000  243.00000  74.000000  148.0  0.926452   \n",
      "\n",
      "             macro avg  weighted avg  \n",
      "precision     0.952544      0.930421  \n",
      "recall        0.934590      0.926452  \n",
      "f1-score      0.940774      0.926372  \n",
      "support    4650.000000   4650.000000  \n",
      "\n",
      "[4 rows x 29 columns]\n",
      "---------------------------------------------------------------\n",
      "Confusion Matrix: \n",
      "[[ 54   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0  78   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0 579   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1\n",
      "    0   0   0   0   0   9   0   0]\n",
      " [  0   0   0 115   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   1   0   0]\n",
      " [  0   0   0   0 167   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0  29   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 298   0   0   0   0  45   0   0   0   0   0   1\n",
      "    0   0   0   0   0   2   0   0]\n",
      " [  0   0   0   0   0   0   0 166   0   0   0   0   0   0   0   1   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 315  64   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   7   0   0]\n",
      " [  0   0   0   0   0   0   0   0  83 162   0   0   0   0   0   0   0   0\n",
      "    1   0   0   0   0   4   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 103   2   0   0   0   0   0   0\n",
      "    0   0   0   0   0  14   0   0]\n",
      " [  0   0   0   0   0   0  49   0   0   0   0 120   0   0   0   0   0   0\n",
      "    0   0   0   0   0   3   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 119   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 138   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 132   0   0   0\n",
      "    0   0   0   0   0   2   0   0]\n",
      " [  0   0   2   0   0   0   0   0   0   0   0   0   0   0   0 185   0   0\n",
      "    1   0   0   0   0   2   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  90   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 104\n",
      "    0   0   0   0   0   6   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  194   0   0   0   0   5   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0 142   0   0   0   6   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0 207   0   0   0   0   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0 282   0   1   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0  92   1   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0 243   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0  27  46   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0 148]]\n",
      "\n",
      "Test Result : \n",
      " ==============================================\n",
      "Accuracy score : 22.70%\n",
      "---------------------------------------------------------------\n",
      "Calssfication Report:\n",
      "                   0          1           2          3          4         5  \\\n",
      "precision   1.000000   0.428571    0.365759   0.034483   0.297297  0.750000   \n",
      "recall      0.444444   0.115385    0.477157   0.025641   0.196429  0.333333   \n",
      "f1-score    0.615385   0.181818    0.414097   0.029412   0.236559  0.461538   \n",
      "support    18.000000  26.000000  197.000000  39.000000  56.000000  9.000000   \n",
      "\n",
      "                    6          7           8          9  ...         19  \\\n",
      "precision    0.200000   0.121212    0.132075   0.053191  ...   0.102564   \n",
      "recall       0.208696   0.071429    0.162791   0.059524  ...   0.080000   \n",
      "f1-score     0.204255   0.089888    0.145833   0.056180  ...   0.089888   \n",
      "support    115.000000  56.000000  129.000000  84.000000  ...  50.000000   \n",
      "\n",
      "                  20         21         22         23         24         25  \\\n",
      "precision   0.530612   0.289157   0.181818   0.308511   0.033333   0.250000   \n",
      "recall      0.376812   0.252632   0.064516   0.716049   0.041667   0.180000   \n",
      "f1-score    0.440678   0.269663   0.095238   0.431227   0.037037   0.209302   \n",
      "support    69.000000  95.000000  31.000000  81.000000  24.000000  50.000000   \n",
      "\n",
      "           accuracy    macro avg  weighted avg  \n",
      "precision   0.22695     0.239814      0.223487  \n",
      "recall      0.22695     0.188650      0.226950  \n",
      "f1-score    0.22695     0.195466      0.213095  \n",
      "support     0.22695  1551.000000   1551.000000  \n",
      "\n",
      "[4 rows x 29 columns]\n",
      "---------------------------------------------------------------\n",
      "Confusion Matrix: \n",
      "[[ 8  0  1  0  0  0  1  0  3  0  0  0  1  0  0  1  0  0  0  0  0  2  0  1\n",
      "   0  0]\n",
      " [ 0  3  1  2  2  0  0  4  0  2  0  0  0  1  0  2  0  1  2  1  1  3  0  0\n",
      "   0  1]\n",
      " [ 0  0 94  4  3  0  7  1 12  2  5  0  2  2  0 12  0 10  7  9  0  6  1 13\n",
      "   3  4]\n",
      " [ 0  1  5  1  1  0  2  2  4  1  2  1  1  2  0  0  0  2  3  1  2  2  0  4\n",
      "   1  1]\n",
      " [ 0  0  7  1 11  1  0  3  1  0  2  0  0  2  1  6  0  1  2  1  4  5  2  5\n",
      "   0  1]\n",
      " [ 0  0  0  0  0  3  0  1  0  1  1  0  0  1  0  0  0  0  0  0  1  1  0  0\n",
      "   0  0]\n",
      " [ 0  0 12  2  0  0 24  1  4  4  2 43  1  0  0  3  0  3  2  1  0  2  1  8\n",
      "   2  0]\n",
      " [ 0  0 12  0  3  0  3  4  4  1  1  0  2  1  1  7  3  1  1  1  0  6  1  2\n",
      "   0  2]\n",
      " [ 0  0  8  2  1  0  2  3 21 57  0  0  2  0  0  2  2  5  2  3  0  0  1 11\n",
      "   6  1]\n",
      " [ 0  0  3  0  0  0  0  0 65  5  0  0  1  0  0  0  0  0  1  0  0  0  1  5\n",
      "   3  0]\n",
      " [ 0  0  2  0  0  0  0  0  0  0 18  2  0  0  0  1  0  0  3  0  0  0  0 10\n",
      "   2  1]\n",
      " [ 0  0  0  0  0  0 47  0  1  0  1  6  0  0  0  0  0  0  1  0  0  0  0  1\n",
      "   0  0]\n",
      " [ 0  0  3  2  0  0  1  2  3  1  1  1  1  0  1  3  0  1  6  2  1  3  0  2\n",
      "   0  5]\n",
      " [ 0  0  7  1  1  0  6  2  5  0  0  1  0  2  3  3  1  1  1  1  2  2  0  3\n",
      "   1  3]\n",
      " [ 0  0  5  3  3  0  2  5  0  0  1  0  2  0  2  3  0  1  1  0  4  8  0  2\n",
      "   0  2]\n",
      " [ 0  0 16  1  1  0  6  1  5  2  0  1  0  1  0  8  0  0  6  2  0  4  0  7\n",
      "   1  1]\n",
      " [ 0  0  6  3  0  0  0  0  0  0  0  2  0  0  0  6  0  1  2  1  0  3  0  5\n",
      "   1  0]\n",
      " [ 0  0 11  1  0  0  1  0  2  2  1  0  0  0  0  1  1  3  1  1  0  0  0 10\n",
      "   2  0]\n",
      " [ 0  0  6  0  2  0  1  1  5  1  5  0  0  0  0  5  0  4 14  2  2  3  0 14\n",
      "   1  1]\n",
      " [ 0  0 10  0  1  0  7  0  5  1  4  0  0  0  0  4  0  1  1  4  0  1  0  9\n",
      "   2  0]\n",
      " [ 0  2  5  0  3  0  3  0  5  0  0  2  1  4  3  0  1  2  0  1 26  5  0  3\n",
      "   1  2]\n",
      " [ 0  0 14  3  4  0  2  2  5  6  0  1  4  2  1  9  3  2  2  2  4 24  2  2\n",
      "   0  1]\n",
      " [ 0  0  2  1  1  0  3  1  3  4  0  1  0  1  0  0  0  3  2  2  1  0  2  3\n",
      "   0  1]\n",
      " [ 0  0  6  0  0  0  1  0  1  1  3  0  0  0  0  1  0  2  4  1  0  0  0 58\n",
      "   3  0]\n",
      " [ 0  0  7  0  0  0  0  0  1  2  0  0  0  0  0  0  0  3  1  0  0  0  0  9\n",
      "   1  0]\n",
      " [ 0  1 14  2  0  0  1  0  4  1  0  1  1  0  1  2  0  0  5  3  1  3  0  1\n",
      "   0  9]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score(model,x_train,y_train,x_test,y_test,train=True)\n",
    "print_score(model,x_train,y_train,x_test,y_test,train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test.drop(columns=['ID'])\n",
    "X_encoded = test_X.copy()\n",
    "X_encoded[categorical_columns] = ordinal_encoder.transform(test_X[categorical_columns]) # 학습 데이터와 동일하게 맞춤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 예측\n",
    "predictions = model.predict(X_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21, 21, 17, ...,  1,  8,  6])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['STES', 'STES', 'PCPG', ..., 'BLCA', 'KIPAN', 'GBMLGG'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_labels = le_subclass.inverse_transform(predictions)\n",
    "original_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SUBCLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_0000</td>\n",
       "      <td>LGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_0001</td>\n",
       "      <td>LGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_0002</td>\n",
       "      <td>LGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_0003</td>\n",
       "      <td>LGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_0004</td>\n",
       "      <td>LGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2541</th>\n",
       "      <td>TEST_2541</td>\n",
       "      <td>LGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2542</th>\n",
       "      <td>TEST_2542</td>\n",
       "      <td>LGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2543</th>\n",
       "      <td>TEST_2543</td>\n",
       "      <td>LGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2544</th>\n",
       "      <td>TEST_2544</td>\n",
       "      <td>LGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2545</th>\n",
       "      <td>TEST_2545</td>\n",
       "      <td>LGG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2546 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID SUBCLASS\n",
       "0     TEST_0000      LGG\n",
       "1     TEST_0001      LGG\n",
       "2     TEST_0002      LGG\n",
       "3     TEST_0003      LGG\n",
       "4     TEST_0004      LGG\n",
       "...         ...      ...\n",
       "2541  TEST_2541      LGG\n",
       "2542  TEST_2542      LGG\n",
       "2543  TEST_2543      LGG\n",
       "2544  TEST_2544      LGG\n",
       "2545  TEST_2545      LGG\n",
       "\n",
       "[2546 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submisson = pd.read_csv(\"./sample_submission.csv\")\n",
    "submisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "submisson[\"SUBCLASS\"] = original_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "submisson.to_csv('./baseline_submission.csv', encoding='UTF-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/supervised_learning.html\n",
    "# sklearn 공식 사이트"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
