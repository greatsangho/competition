{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 암환자 유전체 데이터 기반 암종 분류 AI 모델 개발\n",
    "\n",
    "\n",
    "- '2024 생명연구자원 AI활용 경진대회'는 바이오 데이터를 기반으로 한 AI 기술의 문제 해결 능력을 탐구하는 것을 목표로 합니다. <br>이 대회는 바이오 분야에서 AI 활용의 저변을 확대하고, 복잡한 바이오 데이터를 효율적으로 분석 및 해석할 수 있는 AI 알고리즘 개발에 초점을 맞추고 있습니다. <br><br>\n",
    "- 본 대회의 구체적인 과제는 암환자 유전체 데이터의 변이 정보를 활용하여 암종을 분류하는 AI 모델을 개발하는 것입니다. <br>참가자들은 제공된 학습 데이터셋(암환자 유전체 변이 정보)을 사용하여 특정 변이 정보를 바탕으로 암종을 정확하게 분류할 수 있는 AI 알고리즘을 개발해야 합니다. <br><br>\n",
    "- 이 대회의 궁극적인 목적은 바이오 데이터의 활용도를 높이고, 바이오 분야에서 AI 기술의 적용 가능성을 극대화하며, 인공지능 기술이 실제 바이오 의료 문제 해결에 어떻게 기여할 수 있는지 탐구하는 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r\".\\train.csv\")\n",
    "test = pd.read_csv(r\".\\test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원래 레이블: ACC, 변환된 숫자: 0\n",
      "원래 레이블: BLCA, 변환된 숫자: 1\n",
      "원래 레이블: BRCA, 변환된 숫자: 2\n",
      "원래 레이블: CESC, 변환된 숫자: 3\n",
      "원래 레이블: COAD, 변환된 숫자: 4\n",
      "원래 레이블: DLBC, 변환된 숫자: 5\n",
      "원래 레이블: GBMLGG, 변환된 숫자: 6\n",
      "원래 레이블: HNSC, 변환된 숫자: 7\n",
      "원래 레이블: KIPAN, 변환된 숫자: 8\n",
      "원래 레이블: KIRC, 변환된 숫자: 9\n",
      "원래 레이블: LAML, 변환된 숫자: 10\n",
      "원래 레이블: LGG, 변환된 숫자: 11\n",
      "원래 레이블: LIHC, 변환된 숫자: 12\n",
      "원래 레이블: LUAD, 변환된 숫자: 13\n",
      "원래 레이블: LUSC, 변환된 숫자: 14\n",
      "원래 레이블: OV, 변환된 숫자: 15\n",
      "원래 레이블: PAAD, 변환된 숫자: 16\n",
      "원래 레이블: PCPG, 변환된 숫자: 17\n",
      "원래 레이블: PRAD, 변환된 숫자: 18\n",
      "원래 레이블: SARC, 변환된 숫자: 19\n",
      "원래 레이블: SKCM, 변환된 숫자: 20\n",
      "원래 레이블: STES, 변환된 숫자: 21\n",
      "원래 레이블: TGCT, 변환된 숫자: 22\n",
      "원래 레이블: THCA, 변환된 숫자: 23\n",
      "원래 레이블: THYM, 변환된 숫자: 24\n",
      "원래 레이블: UCEC, 변환된 숫자: 25\n"
     ]
    }
   ],
   "source": [
    "# SUBCLASS 가 범주형이기 때문에 LabelEncoder 사용\n",
    "le_subclass = LabelEncoder()\n",
    "train['SUBCLASS'] = le_subclass.fit_transform(train['SUBCLASS'])\n",
    "\n",
    "# 변환된 레이블 확인\n",
    "for i, label in enumerate(le_subclass.classes_):\n",
    "    print(f\"원래 레이블: {label}, 변환된 숫자: {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 아미노산 코드와 그들의 성질을 매핑\n",
    "amino_acid_properties = {\n",
    "    'A': 'nonpolar',    # Alanine\n",
    "    'R': 'positive',    # Arginine\n",
    "    'N': 'polar',       # Asparagine\n",
    "    'D': 'negative',    # Aspartic Acid\n",
    "    'C': 'polar',       # Cysteine\n",
    "    'Q': 'polar',       # Glutamine\n",
    "    'E': 'negative',    # Glutamic Acid\n",
    "    'G': 'nonpolar',    # Glycine\n",
    "    'H': 'positive',    # Histidine\n",
    "    'I': 'nonpolar',    # Isoleucine\n",
    "    'L': 'nonpolar',    # Leucine\n",
    "    'K': 'positive',    # Lysine\n",
    "    'M': 'nonpolar',    # Methionine\n",
    "    'F': 'aromatic',    # Phenylalanine\n",
    "    'P': 'nonpolar',    # Proline\n",
    "    'S': 'polar',       # Serine\n",
    "    'T': 'polar',       # Threonine\n",
    "    'W': 'aromatic',    # Tryptophan\n",
    "    'Y': 'aromatic',    # Tyrosine\n",
    "    'V': 'nonpolar',    # Valine\n",
    "}\n",
    "\n",
    "# 변이 유형을 분류하는 함수 정의\n",
    "def classify_mutation(mutation):\n",
    "    # 결측치 처리\n",
    "    if pd.isnull(mutation):\n",
    "        return None  # 또는 특정 코드로 지정 가능\n",
    "\n",
    "    mutation = str(mutation).strip()\n",
    "\n",
    "    # WT 체크\n",
    "    if mutation == 'WT':\n",
    "        return 0  # WT (Wild Type)\n",
    "\n",
    "    # 프레임시프트 돌연변이 체크 ('fs' 포함)\n",
    "    if 'fs' in mutation:\n",
    "        return 5  # 프레임시프트 돌연변이\n",
    "\n",
    "    # 중단 돌연변이 체크 ('*' 포함)\n",
    "    if '*' in mutation:\n",
    "        return 4  # 중단 돌연변이\n",
    "\n",
    "    # 돌연변이 패턴 매칭 (예: 'R496Q', 'L1700L')\n",
    "    match = re.match(r'^([A-Z])(\\d+)([A-Z])$', mutation)\n",
    "    if match:\n",
    "        from_aa = match.group(1)  # 원래 아미노산\n",
    "        position = match.group(2) # 위치 (사용하지 않음)\n",
    "        to_aa = match.group(3)    # 변이된 아미노산\n",
    "\n",
    "        # 침묵 돌연변이 체크 (아미노산이 동일한 경우)\n",
    "        if from_aa == to_aa:\n",
    "            return 1  # 침묵 돌연변이\n",
    "\n",
    "        # 아미노산 성질 가져오기\n",
    "        from_property = amino_acid_properties.get(from_aa)\n",
    "        to_property = amino_acid_properties.get(to_aa)\n",
    "\n",
    "        # 아미노산 코드가 유효한지 확인\n",
    "        if from_property is None or to_property is None:\n",
    "            return 6  # 알 수 없는 아미노산 코드\n",
    "\n",
    "        # 보존적 돌연변이 체크 (아미노산 성질이 동일한 경우)\n",
    "        if from_property == to_property:\n",
    "            return 2  # 보존적 돌연변이\n",
    "        else:\n",
    "            return 3  # 비보존적 돌연변이\n",
    "    else:\n",
    "        # 패턴 매칭 실패한 경우\n",
    "        return 6  # 매칭 실패한 경우 6 반환\n",
    "\n",
    "# 다중 치환을 처리하는 함수 정의\n",
    "def classify_multiple_mutations(mutation_string):\n",
    "    # 결측치 처리\n",
    "    if pd.isnull(mutation_string):\n",
    "        return None  # 또는 특정 코드로 지정 가능\n",
    "\n",
    "    # 변이 문자열을 공백으로 분리\n",
    "    mutations = str(mutation_string).strip().split()\n",
    "\n",
    "    labels = []\n",
    "    for mutation in mutations:\n",
    "        label = classify_mutation(mutation)\n",
    "        if label is not None:\n",
    "            labels.append(label)\n",
    "    if labels:\n",
    "        # 가장 높은 값을 반환\n",
    "        return max(labels)\n",
    "    else:\n",
    "        return None  # 또는 특정 코드로 지정 가능\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID  SUBCLASS  A2M  AAAS  AADAT  AARS1  ABAT  ABCA1  ABCA2  ABCA3  \\\n",
      "0  TRAIN_0000         8    0     0      0      0     0      0      0      0   \n",
      "1  TRAIN_0001        19    0     0      0      0     0      0      0      0   \n",
      "2  TRAIN_0002        20    1     0      0      0     0      0      0      0   \n",
      "3  TRAIN_0003         9    0     0      0      0     0      0      0      0   \n",
      "4  TRAIN_0004         6    0     0      0      0     0      0      0      0   \n",
      "\n",
      "   ...  ZNF292  ZNF365  ZNF639  ZNF707  ZNFX1  ZNRF4  ZPBP  ZW10  ZWINT  ZYX  \n",
      "0  ...       0       0       0       0      0      0     0     0      0    0  \n",
      "1  ...       0       0       0       0      0      0     0     0      0    0  \n",
      "2  ...       0       0       0       0      0      0     0     0      0    0  \n",
      "3  ...       0       0       0       0      0      0     0     0      0    0  \n",
      "4  ...       0       0       0       0      0      0     0     0      0    0  \n",
      "\n",
      "[5 rows x 4386 columns]\n"
     ]
    }
   ],
   "source": [
    "# 제외할 열 목록 (예시로 'ID'와 'SUBCLASS'를 제외)\n",
    "exclude_cols = ['ID', 'SUBCLASS']\n",
    "\n",
    "# 변이 데이터가 있는 열 목록\n",
    "mutation_cols = [col for col in train.columns if col not in exclude_cols]\n",
    "\n",
    "# 각 열에 함수 적용\n",
    "for col in mutation_cols:\n",
    "    train[col] = train[col].apply(classify_multiple_mutations)\n",
    "\n",
    "# 결과 출력 (일부 열만 표시)\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ID  SUBCLASS  A2M  AAAS  AADAT  AARS1  ABAT  ABCA1  ABCA2  ABCA3  \\\n",
      "0   TRAIN_0000         8    0     0      0      0     0      0      0      0   \n",
      "1   TRAIN_0001        19    0     0      0      0     0      0      0      0   \n",
      "2   TRAIN_0002        20    1     0      0      0     0      0      0      0   \n",
      "3   TRAIN_0003         9    0     0      0      0     0      0      0      0   \n",
      "4   TRAIN_0004         6    0     0      0      0     0      0      0      0   \n",
      "5   TRAIN_0005        21    0     0      2      0     0      0      0      0   \n",
      "6   TRAIN_0006         2    0     0      0      0     0      0      0      0   \n",
      "7   TRAIN_0007        23    0     0      0      0     0      0      0      0   \n",
      "8   TRAIN_0008        12    0     0      0      0     0      0      0      0   \n",
      "9   TRAIN_0009        21    0     0      0      0     0      0      0      0   \n",
      "10  TRAIN_0010        21    0     0      0      0     0      0      0      0   \n",
      "11  TRAIN_0011         7    0     0      0      0     0      0      0      0   \n",
      "12  TRAIN_0012         9    0     0      0      0     0      0      0      0   \n",
      "13  TRAIN_0013        16    0     0      0      0     0      0      0      0   \n",
      "14  TRAIN_0014        20    0     0      0      0     0      3      0      0   \n",
      "15  TRAIN_0015        15    0     0      0      0     0      0      0      0   \n",
      "16  TRAIN_0016         8    0     0      0      0     0      0      0      0   \n",
      "17  TRAIN_0017         8    0     0      0      0     0      0      0      0   \n",
      "18  TRAIN_0018         2    0     0      0      0     0      0      0      0   \n",
      "\n",
      "    ...  ZNF292  ZNF365  ZNF639  ZNF707  ZNFX1  ZNRF4  ZPBP  ZW10  ZWINT  ZYX  \n",
      "0   ...       0       0       0       0      0      0     0     0      0    0  \n",
      "1   ...       0       0       0       0      0      0     0     0      0    0  \n",
      "2   ...       0       0       0       0      0      0     0     0      0    0  \n",
      "3   ...       0       0       0       0      0      0     0     0      0    0  \n",
      "4   ...       0       0       0       0      0      0     0     0      0    0  \n",
      "5   ...       0       0       0       1      0      0     0     0      0    0  \n",
      "6   ...       0       0       0       0      0      0     0     0      0    0  \n",
      "7   ...       0       0       0       0      0      0     0     0      0    0  \n",
      "8   ...       0       0       0       0      0      0     0     0      0    0  \n",
      "9   ...       0       0       0       0      0      0     0     0      0    0  \n",
      "10  ...       0       0       0       0      0      0     0     0      0    0  \n",
      "11  ...       0       0       0       0      3      1     0     0      0    0  \n",
      "12  ...       0       0       0       0      5      0     0     0      0    0  \n",
      "13  ...       0       0       0       0      0      0     0     0      0    0  \n",
      "14  ...       0       0       0       0      0      0     0     0      0    0  \n",
      "15  ...       0       0       0       0      0      0     0     0      0    0  \n",
      "16  ...       0       0       0       0      0      0     0     0      0    0  \n",
      "17  ...       0       0       0       0      0      0     0     0      0    0  \n",
      "18  ...       0       0       0       0      0      0     0     0      0    0  \n",
      "\n",
      "[19 rows x 4386 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train.head(19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID  A2M  AAAS  AADAT  AARS1  ABAT  ABCA1  ABCA2  ABCA3  ABCA4  ...  \\\n",
      "0  TEST_0000    0     0      0      0     0      0      0      0      0  ...   \n",
      "1  TEST_0001    0     0      0      0     0      3      0      0      0  ...   \n",
      "2  TEST_0002    0     0      0      0     0      0      0      0      0  ...   \n",
      "3  TEST_0003    0     0      0      0     0      0      0      0      0  ...   \n",
      "4  TEST_0004    0     0      0      0     0      0      0      0      0  ...   \n",
      "\n",
      "   ZNF292  ZNF365  ZNF639  ZNF707  ZNFX1  ZNRF4  ZPBP  ZW10  ZWINT  ZYX  \n",
      "0       0       0       0       0      0      0     0     0      0    0  \n",
      "1       0       0       0       0      0      5     0     0      0    0  \n",
      "2       0       0       0       0      0      0     0     0      0    0  \n",
      "3       0       0       0       0      0      0     0     0      0    0  \n",
      "4       0       0       0       0      0      0     0     0      0    0  \n",
      "\n",
      "[5 rows x 4385 columns]\n"
     ]
    }
   ],
   "source": [
    "# 제외할 열 목록 (예시로 'ID'와 'SUBCLASS'를 제외)\n",
    "exclude_cols = ['ID', 'SUBCLASS']\n",
    "\n",
    "# 변이 데이터가 있는 열 목록\n",
    "mutation_cols = [col for col in train.columns if col not in exclude_cols]\n",
    "\n",
    "# 각 열에 함수 적용\n",
    "for col in mutation_cols:\n",
    "    test[col] = test[col].apply(classify_multiple_mutations)\n",
    "\n",
    "# 결과 출력 (일부 열만 표시)\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Define and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 66\u001b[0m\n\u001b[0;32m     54\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulti_logloss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_class\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(y\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m     63\u001b[0m }\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Create and train the LightGBM model using LGBMClassifier\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mlgb\u001b[49m\u001b[38;5;241m.\u001b[39mLGBMClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m     67\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train_resampled, y_train_resampled)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Make predictions on the train and test data\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lgb' is not defined"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score, classification_report\n",
    "# # import lightgbm as lgb\n",
    "# import numpy as np\n",
    "# from itertools import product\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "# from lightgbm import LGBMClassifier\n",
    "\n",
    "# voting_clf = VotingClassifier(\n",
    "#     estimators=[\n",
    "#         ('lr',LogisticRegression()),\n",
    "#         ('rf',RandomForestClassifier()),\n",
    "#         ('svc',SVC()),\n",
    "#         ('lgb',LGBMClassifier())\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# # 1. 데이터 준비\n",
    "# # 타겟: 'SUBCLASS', 특징: 'SUBCLASS'와 'ID'를 제외한 나머지 열\n",
    "# X = train.drop(columns=['SUBCLASS', 'ID'])  # 특징 데이터 (SUBCLASS를 제외한 모든 열)\n",
    "# y = train['SUBCLASS']  # 타겟 데이터 (SUBCLASS)\n",
    "\n",
    "# # 2. 학습 세트와 테스트 세트로 데이터 나누기\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# ss = StandardScaler()\n",
    "# x_train_scaled = ss.fit_transform(X_train)\n",
    "# x_test_scaled =  ss.fit_transform(X_test)\n",
    "\n",
    "# # Apply SMOTE to balance the training data\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X_train_resampled, y_train_resampled = smote.fit_resample(x_train_scaled, y_train)\n",
    "\n",
    "# # Define a set of hyperparameters to iterate over for tuning\n",
    "# learning_rates = [0.001, 0.05, 0.01, 0.1]\n",
    "# num_leaves_options = [5, 10, 15]\n",
    "# max_depths = [-1, 5, 10]  # -1 indicates no limit\n",
    "# boosting_types = ['gbdt']  # 'dart', 'goss'\n",
    "\n",
    "# # Create a list of all combinations of hyperparameters\n",
    "# tuning_params = list(product(learning_rates, num_leaves_options, max_depths, boosting_types))\n",
    "\n",
    "# best_train_accuracy = 0\n",
    "# best_test_accuracy = 0\n",
    "# best_params = None\n",
    "\n",
    "# for lr, num_leaves, max_depth, boosting_type in tuning_params:\n",
    "#     # Set parameters for the current iteration\n",
    "#     params = {\n",
    "#         'objective': 'multiclass',\n",
    "#         'metric': 'multi_logloss',\n",
    "#         'boosting_type': boosting_type,\n",
    "#         'learning_rate': lr,\n",
    "#         'num_leaves': num_leaves,\n",
    "#         'max_depth': max_depth,\n",
    "#         'verbose': -1,\n",
    "#         'num_class': len(y.unique())\n",
    "#     }\n",
    "    \n",
    "#     # Create and train the LightGBM model using LGBMClassifier\n",
    "#     model = LGBMClassifier(**params)\n",
    "#     model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "#     # Make predictions on the train and test data\n",
    "#     y_train_pred = model.predict(X_train_resampled)\n",
    "#     y_test_pred = model.predict(X_test)\n",
    "    \n",
    "#     # Calculate accuracy\n",
    "#     train_accuracy = accuracy_score(y_train_resampled, y_train_pred)\n",
    "#     test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "#     # Check if this is the best model so far\n",
    "#     if test_accuracy > best_test_accuracy:\n",
    "#         best_train_accuracy = train_accuracy\n",
    "#         best_test_accuracy = test_accuracy\n",
    "#         best_params = (lr, num_leaves, max_depth, boosting_type)\n",
    "#         best_model = model  # Save the best model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score, classification_report\n",
    "# import lightgbm as lgb\n",
    "# import numpy as np\n",
    "# from itertools import product\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# # 1. 데이터 준비\n",
    "# # 타겟: 'SUBCLASS', 특징: 'SUBCLASS'와 'ID'를 제외한 나머지 열\n",
    "# X = train.drop(columns=['SUBCLASS', 'ID'])  # 특징 데이터 (SUBCLASS를 제외한 모든 열)\n",
    "# y = train['SUBCLASS']  # 타겟 데이터 (SUBCLASS)\n",
    "\n",
    "# # 2. 학습 세트와 테스트 세트로 데이터 나누기\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# ss = StandardScaler()\n",
    "# x_train_scaled = ss.fit_transform(X_train)\n",
    "# x_test_scaled =  ss.fit_transform(X_test)\n",
    "\n",
    "# # Apply SMOTE to balance the training data\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X_train_resampled, y_train_resampled = smote.fit_resample(x_train_scaled, y_train)\n",
    "\n",
    "# # Define a set of hyperparameters to iterate over for tuning\n",
    "# learning_rates = [0.001, 0.05, 0.01, 0.1]\n",
    "# num_leaves_options = [5, 10, 15]\n",
    "# max_depths = [-1, 5, 10]  # -1 indicates no limit\n",
    "# boosting_types = ['gbdt']  # 'dart', 'goss'\n",
    "\n",
    "# # Create a list of all combinations of hyperparameters\n",
    "# tuning_params = list(product(learning_rates, num_leaves_options, max_depths, boosting_types))\n",
    "\n",
    "# best_train_accuracy = 0\n",
    "# best_test_accuracy = 0\n",
    "# best_params = None\n",
    "\n",
    "# for lr, num_leaves, max_depth, boosting_type in tuning_params:\n",
    "#     # Set parameters for the current iteration\n",
    "#     params = {\n",
    "#         'objective': 'multiclass',\n",
    "#         'metric': 'multi_logloss',\n",
    "#         'boosting_type': boosting_type,\n",
    "#         'learning_rate': lr,\n",
    "#         'num_leaves': num_leaves,\n",
    "#         'max_depth': max_depth,\n",
    "#         'verbose': -1,\n",
    "#         'num_class': len(y.unique())\n",
    "#     }\n",
    "    \n",
    "#     # Create and train the LightGBM model using LGBMClassifier\n",
    "#     model = lgb.LGBMClassifier(**params)\n",
    "#     model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "#     # Make predictions on the train and test data\n",
    "#     y_train_pred = model.predict(X_train_resampled)\n",
    "#     y_test_pred = model.predict(X_test)\n",
    "    \n",
    "#     # Calculate accuracy\n",
    "#     train_accuracy = accuracy_score(y_train_resampled, y_train_pred)\n",
    "#     test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "#     # Check if this is the best model so far\n",
    "#     if test_accuracy > best_test_accuracy:\n",
    "#         best_train_accuracy = train_accuracy\n",
    "#         best_test_accuracy = test_accuracy\n",
    "#         best_params = (lr, num_leaves, max_depth, boosting_type)\n",
    "#         best_model = model  # Save the best model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pypandas\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:50:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.29734085414987915\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.64      0.75        14\n",
      "           1       0.33      0.05      0.08        21\n",
      "           2       0.55      0.49      0.52       157\n",
      "           3       0.11      0.06      0.08        31\n",
      "           4       0.74      0.62      0.67        45\n",
      "           5       0.50      0.14      0.22         7\n",
      "           6       0.20      0.20      0.20        92\n",
      "           7       0.35      0.24      0.29        45\n",
      "           8       0.11      0.11      0.11       103\n",
      "           9       0.10      0.12      0.11        67\n",
      "          10       0.36      0.62      0.45        32\n",
      "          11       0.12      0.15      0.14        46\n",
      "          12       0.53      0.26      0.35        31\n",
      "          13       0.00      0.00      0.00        37\n",
      "          14       0.19      0.14      0.16        36\n",
      "          15       0.21      0.31      0.25        51\n",
      "          16       0.11      0.08      0.10        24\n",
      "          17       0.12      0.24      0.16        29\n",
      "          18       0.25      0.25      0.25        53\n",
      "          19       0.10      0.12      0.11        40\n",
      "          20       0.64      0.49      0.56        55\n",
      "          21       0.34      0.30      0.32        76\n",
      "          22       0.00      0.00      0.00        25\n",
      "          23       0.53      0.65      0.58        65\n",
      "          24       0.10      0.53      0.17        19\n",
      "          25       0.62      0.45      0.52        40\n",
      "\n",
      "    accuracy                           0.30      1241\n",
      "   macro avg       0.31      0.28      0.28      1241\n",
      "weighted avg       0.32      0.30      0.30      1241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 1. 데이터 준비\n",
    "# 타겟: 'SUBCLASS', 특징: 'SUBCLASS'와 'ID'를 제외한 나머지 열\n",
    "X = train.drop(columns=['SUBCLASS', 'ID'])  # 특징 데이터 (SUBCLASS를 제외한 모든 열)\n",
    "y = train['SUBCLASS']  # 타겟 데이터 (SUBCLASS)\n",
    "\n",
    "# 2. 학습 세트와 테스트 세트로 데이터 나누기\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# 3. 데이터 스케일링\n",
    "ss = StandardScaler()\n",
    "X_train_scaled = ss.fit_transform(X_train)\n",
    "X_test_scaled = ss.transform(X_test)  # Use transform instead of fit_transform on test set\n",
    "\n",
    "# 4. SMOTE 적용하여 학습 데이터 균형 맞추기\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# 5. 개별 모델 정의\n",
    "lightgbm_model = lgb.LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    metric='multi_logloss',\n",
    "    boosting_type='gbdt',\n",
    "    learning_rate=0.1,\n",
    "    num_leaves=15,\n",
    "    max_depth=10,\n",
    "    verbose=-1,\n",
    "    num_class=len(y.unique())\n",
    ")\n",
    "\n",
    "xgboost_model = xgb.XGBClassifier(\n",
    "    objective='multi:softprob',\n",
    "    eval_metric='mlogloss',\n",
    "    use_label_encoder=False,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=10,\n",
    "    n_estimators=100\n",
    ")\n",
    "\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "svm_model = SVC(probability=True)  # Enable probability estimates for voting\n",
    "\n",
    "random_forest_model = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# 6. Voting Classifier 정의 (앙상블)\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lightgbm', lightgbm_model),\n",
    "        ('xgboost', xgboost_model),\n",
    "        ('logistic', logistic_model),\n",
    "        ('svm', svm_model),\n",
    "        ('random_forest', random_forest_model)\n",
    "    ],\n",
    "    voting='soft'  # Use soft voting to consider probabilities of each class\n",
    ")\n",
    "\n",
    "# 7. 모델 학습 및 평가\n",
    "voting_clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# 예측 및 평가\n",
    "y_pred = voting_clf.predict(X_test_scaled)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Train Accuracy: 0.00%\n",
      "Best Test Accuracy: 0.00%\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Train Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_train_accuracy\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Test Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_test_accuracy\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Parameters: Learning Rate=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mbest_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Num Leaves=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Max Depth=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Boosting Type=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params[\u001b[38;5;241m3\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Generate and print classification report for the best model on test data\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mClassification Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Print the best results and parameters\n",
    "print(f\"Best Train Accuracy: {best_train_accuracy * 100:.2f}%\")\n",
    "print(f\"Best Test Accuracy: {best_test_accuracy * 100:.2f}%\")\n",
    "print(f\"Best Parameters: Learning Rate={best_params[0]}, Num Leaves={best_params[1]}, Max Depth={best_params[2]}, Boosting Type={best_params[3]}\")\n",
    "\n",
    "# Generate and print classification report for the best model on test data\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# Use the best model to make predictions on the test set and store them\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "# Print or save predictions as needed\n",
    "print(\"Predictions on Test Set:\")\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(columns=['ID'])\n",
    "# X_encoded = test_X.copy()\n",
    "# X_encoded[categorical_columns] = ordinal_encoder.transform(test_X[categorical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21, 25, 23, ...,  3, 10,  6])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_labels = le_subclass.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "submisson = pd.read_csv(\"./sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "submisson[\"SUBCLASS\"] = original_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "submisson.to_csv('./baseline_submission.csv', encoding='UTF-8-sig', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
