{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 암환자 유전체 데이터 기반 암종 분류 AI 모델 개발\n",
    "\n",
    "\n",
    "- '2024 생명연구자원 AI활용 경진대회'는 바이오 데이터를 기반으로 한 AI 기술의 문제 해결 능력을 탐구하는 것을 목표로 합니다. <br>이 대회는 바이오 분야에서 AI 활용의 저변을 확대하고, 복잡한 바이오 데이터를 효율적으로 분석 및 해석할 수 있는 AI 알고리즘 개발에 초점을 맞추고 있습니다. <br><br>\n",
    "- 본 대회의 구체적인 과제는 암환자 유전체 데이터의 변이 정보를 활용하여 암종을 분류하는 AI 모델을 개발하는 것입니다. <br>참가자들은 제공된 학습 데이터셋(암환자 유전체 변이 정보)을 사용하여 특정 변이 정보를 바탕으로 암종을 정확하게 분류할 수 있는 AI 알고리즘을 개발해야 합니다. <br><br>\n",
    "- 이 대회의 궁극적인 목적은 바이오 데이터의 활용도를 높이고, 바이오 분야에서 AI 기술의 적용 가능성을 극대화하며, 인공지능 기술이 실제 바이오 의료 문제 해결에 어떻게 기여할 수 있는지 탐구하는 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "import xgboost as xgb\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모든 행이 WT인 컬럼 제거 (train, test 모두)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 데이터프레임에서 모든 값이 'WT'인 컬럼을 각각 찾음\n",
    "columns_all_wt_train = train.columns[(train == 'WT').all(axis=0)]\n",
    "columns_all_wt_test = test.columns[(test == 'WT').all(axis=0)]\n",
    "\n",
    "# train과 test에서 모든 값이 'WT'인 컬럼의 합집합 찾기\n",
    "union_columns = columns_all_wt_train.union(columns_all_wt_test)\n",
    "\n",
    "# 합집합에 해당하는 컬럼을 train과 test에서 삭제\n",
    "train = train.drop(columns=union_columns)\n",
    "test = test.drop(columns=union_columns)\n",
    "\n",
    "# 결과 확인\n",
    "# print(\"모든 값이 'WT'인 컬럼을 삭제한 train 데이터프레임:\")\n",
    "# print(train.head())\n",
    "# print(\"모든 값이 'WT'인 컬럼을 삭제한 test 데이터프레임:\")\n",
    "# print(test.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 표기 규칙 수정 (47s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 돌연변이 표기 수정 규칙 적용 함수\n",
    "def process_mutations(mutation_string):\n",
    "    if pd.isnull(mutation_string):\n",
    "        return None  # 결측치 처리\n",
    "\n",
    "    # 여러 개의 변이를 ',' 또는 ' ' 로 나누어 처리\n",
    "    mutations = mutation_string.split(',')\n",
    "    processed_mutations = []\n",
    "\n",
    "    for mutation in mutations:\n",
    "        mutation = mutation.strip()\n",
    "        \n",
    "        # 다중 변이 패턴: '711_712FL>FL' -> 'F711F L712L'로 수정\n",
    "        multi_match = re.match(r'^(\\d+_\\d+)([A-Z]+)>([A-Z*]+)$', mutation)\n",
    "        if multi_match:\n",
    "            positions = multi_match.group(1)  # '197_198'\n",
    "            from_aa_seq = multi_match.group(2)  # 'YQ'\n",
    "            to_aa_seq = multi_match.group(3)    # '**' 또는 특정 아미노산 코드\n",
    "\n",
    "            pos_list = positions.split('_')\n",
    "            new_mutation = []\n",
    "            for i, (from_aa, to_aa) in enumerate(zip(from_aa_seq, to_aa_seq)):\n",
    "                # '*'와 같은 특수한 문자가 들어오면 그대로 유지\n",
    "                if to_aa == '*':\n",
    "                    new_mutation.append(f\"{from_aa}{pos_list[i]}*\")\n",
    "                else:\n",
    "                    new_mutation.append(f\"{from_aa}{pos_list[i]}{to_aa}\")\n",
    "            processed_mutations.append(' '.join(new_mutation))\n",
    "\n",
    "        # '*' 돌연변이 패턴은 그대로 추가\n",
    "        elif '*' in mutation:\n",
    "            processed_mutations.append(mutation)\n",
    "        \n",
    "        # 기본적인 패턴: 그대로 추가\n",
    "        else:\n",
    "            processed_mutations.append(mutation)\n",
    "\n",
    "    # 중복 제거 후 반환\n",
    "    unique_mutations = list(dict.fromkeys(processed_mutations))  # 중복 제거\n",
    "    return ', '.join(unique_mutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_18456\\1431569657.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  train_processed = train.applymap(process_mutations)\n"
     ]
    }
   ],
   "source": [
    "train_processed = train.applymap(process_mutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_18456\\4212444730.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  test_processed = test.applymap(process_mutations)\n"
     ]
    }
   ],
   "source": [
    "test_processed = test.applymap(process_mutations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### misense driver 적용 (1m 26s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "misense_driver = pd.read_csv('missense_driver.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "misense_driver['Gene name'] = misense_driver['Gene name'].str.split('_').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes = train.drop(columns=['ID','SUBCLASS']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "misense_driver = misense_driver[misense_driver['Gene name'].isin(yes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "misense_driver_dict = misense_driver.groupby('Gene name')['Mutation'].apply(lambda x: np.array(x)).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 다중 돌연변이를 처리하는 함수\n",
    "def update_misense_driver(train, misense_driver_dict):\n",
    "    # 유전자 열만 추출 ('ID', 'SUBCLASS' 제외)\n",
    "    gene_columns = [col for col in train.columns if col not in ['ID', 'SUBCLASS']]\n",
    "    \n",
    "    # 각 유전자 열에 대해 처리\n",
    "    for gene in gene_columns:\n",
    "        if gene in misense_driver_dict:  # misense_driver_dict에 해당 유전자가 존재하는지 확인\n",
    "            # 해당 유전자의 돌연변이 리스트 가져오기\n",
    "            mutation_list = misense_driver_dict[gene]\n",
    "            \n",
    "            # 해당 열에 대해 처리\n",
    "            def process_mutations(mutation_string):\n",
    "                if pd.isnull(mutation_string):  # 결측치 처리\n",
    "                    return mutation_string\n",
    "\n",
    "                # 돌연변이 문자열을 공백으로 분리하여 각 변이를 개별적으로 처리\n",
    "                mutations = mutation_string.split()\n",
    "                \n",
    "                # 각 변이가 mutation_list에 있는지 확인하여 30으로 교체\n",
    "                processed_mutations = [str(30) if mut in mutation_list else mut for mut in mutations]\n",
    "                \n",
    "                # 변이를 다시 공백으로 연결하여 반환\n",
    "                return ' '.join(processed_mutations)\n",
    "            \n",
    "            # apply 함수를 사용하여 각 셀에 대해 처리\n",
    "            train[gene] = train[gene].apply(process_mutations)\n",
    "    \n",
    "    return train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수 적용\n",
    "train_processed2 = update_misense_driver(train_processed, misense_driver_dict)\n",
    "test_processed2 = update_misense_driver(test_processed, misense_driver_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SUBCLASS</th>\n",
       "      <th>A2M</th>\n",
       "      <th>AAAS</th>\n",
       "      <th>AADAT</th>\n",
       "      <th>ABAT</th>\n",
       "      <th>ABCA1</th>\n",
       "      <th>ABCA2</th>\n",
       "      <th>ABCA3</th>\n",
       "      <th>ABCA4</th>\n",
       "      <th>...</th>\n",
       "      <th>ZNF292</th>\n",
       "      <th>ZNF365</th>\n",
       "      <th>ZNF639</th>\n",
       "      <th>ZNF707</th>\n",
       "      <th>ZNFX1</th>\n",
       "      <th>ZNRF4</th>\n",
       "      <th>ZPBP</th>\n",
       "      <th>ZW10</th>\n",
       "      <th>ZWINT</th>\n",
       "      <th>ZYX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>TRAIN_1758</td>\n",
       "      <td>STES</td>\n",
       "      <td>30</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>T128T</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>M456T</td>\n",
       "      <td>30</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>TRAIN_1802</td>\n",
       "      <td>LUAD</td>\n",
       "      <td>30</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>TRAIN_1818</td>\n",
       "      <td>COAD</td>\n",
       "      <td>30</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>A1913D</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>TRAIN_2477</td>\n",
       "      <td>BRCA</td>\n",
       "      <td>30</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>R162C</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3729</th>\n",
       "      <td>TRAIN_3729</td>\n",
       "      <td>COAD</td>\n",
       "      <td>30</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID SUBCLASS A2M AAAS AADAT ABAT ABCA1 ABCA2 ABCA3 ABCA4  ...  \\\n",
       "1758  TRAIN_1758     STES  30   WT    WT   WT    WT    WT    WT    WT  ...   \n",
       "1802  TRAIN_1802     LUAD  30   WT    WT   WT    WT    WT    WT    WT  ...   \n",
       "1818  TRAIN_1818     COAD  30   WT    WT   WT    WT    WT    WT    WT  ...   \n",
       "2477  TRAIN_2477     BRCA  30   WT    WT   WT    WT    WT    WT    WT  ...   \n",
       "3729  TRAIN_3729     COAD  30   WT    WT   WT    WT    WT    WT    WT  ...   \n",
       "\n",
       "      ZNF292 ZNF365 ZNF639 ZNF707  ZNFX1  ZNRF4 ZPBP ZW10 ZWINT ZYX  \n",
       "1758      WT  T128T     WT     WT  M456T     30   WT   WT    WT  WT  \n",
       "1802      WT     WT     WT     WT     WT     WT   WT   WT    WT  WT  \n",
       "1818  A1913D     WT     WT     WT     WT     WT   WT   WT    WT  WT  \n",
       "2477      WT     WT     WT     WT     WT  R162C   WT   WT    WT  WT  \n",
       "3729      WT     WT     WT     WT     WT     WT   WT   WT    WT  WT  \n",
       "\n",
       "[5 rows x 4227 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_processed2[train_processed2['A2M'] == '30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>A2M</th>\n",
       "      <th>AAAS</th>\n",
       "      <th>AADAT</th>\n",
       "      <th>ABAT</th>\n",
       "      <th>ABCA1</th>\n",
       "      <th>ABCA2</th>\n",
       "      <th>ABCA3</th>\n",
       "      <th>ABCA4</th>\n",
       "      <th>ABCA5</th>\n",
       "      <th>...</th>\n",
       "      <th>ZNF292</th>\n",
       "      <th>ZNF365</th>\n",
       "      <th>ZNF639</th>\n",
       "      <th>ZNF707</th>\n",
       "      <th>ZNFX1</th>\n",
       "      <th>ZNRF4</th>\n",
       "      <th>ZPBP</th>\n",
       "      <th>ZW10</th>\n",
       "      <th>ZWINT</th>\n",
       "      <th>ZYX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2370</th>\n",
       "      <td>TEST_2370</td>\n",
       "      <td>30</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>V1179I</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 4226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID A2M AAAS AADAT ABAT ABCA1 ABCA2 ABCA3 ABCA4 ABCA5  ... ZNF292  \\\n",
       "2370  TEST_2370  30   WT    WT   WT    WT    WT    WT    WT    WT  ...     WT   \n",
       "\n",
       "     ZNF365 ZNF639 ZNF707   ZNFX1 ZNRF4 ZPBP ZW10 ZWINT ZYX  \n",
       "2370     WT     WT     WT  V1179I    WT   WT   WT    WT  WT  \n",
       "\n",
       "[1 rows x 4226 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_processed2[test_processed2['A2M'] == '30']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### missense passenger 적용 (2m 44s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "misense_passenger = pd.read_csv('missense_passenger.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "misense_passenger['Gene name'] = misense_passenger['Gene name'].str.split('_').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes = train.drop(columns=['ID','SUBCLASS']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "misense_passenger = misense_passenger[misense_passenger['Gene name'].isin(yes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "misense_passenger_dict = misense_passenger.groupby('Gene name')['Mutation'].apply(lambda x: np.array(x)).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_misense_passenger(train, misense_passenger_dict):\n",
    "    # 유전자 열만 추출 ('ID', 'SUBCLASS' 제외)\n",
    "    gene_columns = [col for col in train.columns if col not in ['ID', 'SUBCLASS']]\n",
    "    \n",
    "    # 각 유전자 열에 대해 처리\n",
    "    for gene in gene_columns:\n",
    "        if gene in misense_passenger_dict:  # misense_driver_dict에 해당 유전자가 존재하는지 확인\n",
    "            # 해당 유전자의 돌연변이 리스트 가져오기\n",
    "            mutation_list = misense_passenger_dict[gene]\n",
    "            \n",
    "            # 해당 열에 대해 값이 돌연변이 리스트에 있는지 확인하고 있으면 30으로 대체\n",
    "            #train[gene] = train[gene].apply(lambda x: 0 if x in mutation_list else x )\n",
    "            train[gene] = train[gene].apply(lambda x: str(0) if not isinstance(x, (int, float)) and x in mutation_list else x)\n",
    "\n",
    "    \n",
    "    return train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed3=update_misense_passenger(train_processed2,misense_passenger_dict)\n",
    "test_processed3=update_misense_passenger(test_processed2,misense_passenger_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SUBCLASS</th>\n",
       "      <th>A2M</th>\n",
       "      <th>AAAS</th>\n",
       "      <th>AADAT</th>\n",
       "      <th>ABAT</th>\n",
       "      <th>ABCA1</th>\n",
       "      <th>ABCA2</th>\n",
       "      <th>ABCA3</th>\n",
       "      <th>ABCA4</th>\n",
       "      <th>...</th>\n",
       "      <th>ZNF292</th>\n",
       "      <th>ZNF365</th>\n",
       "      <th>ZNF639</th>\n",
       "      <th>ZNF707</th>\n",
       "      <th>ZNFX1</th>\n",
       "      <th>ZNRF4</th>\n",
       "      <th>ZPBP</th>\n",
       "      <th>ZW10</th>\n",
       "      <th>ZWINT</th>\n",
       "      <th>ZYX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>TRAIN_0120</td>\n",
       "      <td>KIPAN</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>TRAIN_0318</td>\n",
       "      <td>BLCA</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>TRAIN_0669</td>\n",
       "      <td>BLCA</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2136</th>\n",
       "      <td>TRAIN_2136</td>\n",
       "      <td>LUAD</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306</th>\n",
       "      <td>TRAIN_2306</td>\n",
       "      <td>BRCA</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2389</th>\n",
       "      <td>TRAIN_2389</td>\n",
       "      <td>COAD</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2510</th>\n",
       "      <td>TRAIN_2510</td>\n",
       "      <td>LUAD</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>E291E</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>TRAIN_2746</td>\n",
       "      <td>BRCA</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2969</th>\n",
       "      <td>TRAIN_2969</td>\n",
       "      <td>BLCA</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>TRAIN_2984</td>\n",
       "      <td>COAD</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>0</td>\n",
       "      <td>S2192N F1854F K376R</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>V1698V E1295* S1071L</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3715</th>\n",
       "      <td>TRAIN_3715</td>\n",
       "      <td>UCEC</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4523</th>\n",
       "      <td>TRAIN_4523</td>\n",
       "      <td>BLCA</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5163</th>\n",
       "      <td>TRAIN_5163</td>\n",
       "      <td>KIPAN</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5211</th>\n",
       "      <td>TRAIN_5211</td>\n",
       "      <td>KIRC</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5703</th>\n",
       "      <td>TRAIN_5703</td>\n",
       "      <td>KIRC</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5789</th>\n",
       "      <td>TRAIN_5789</td>\n",
       "      <td>SKCM</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>A2037V</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>R1223*</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>S150F</td>\n",
       "      <td>WT</td>\n",
       "      <td>E102K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows × 4227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID SUBCLASS A2M AAAS AADAT ABAT                ABCA1 ABCA2  \\\n",
       "120   TRAIN_0120    KIPAN   0   WT    WT   WT                   WT    WT   \n",
       "318   TRAIN_0318     BLCA   0   WT    WT   WT                   WT    WT   \n",
       "669   TRAIN_0669     BLCA   0   WT    WT   WT                   WT    WT   \n",
       "2136  TRAIN_2136     LUAD   0   WT    WT   WT                    0    WT   \n",
       "2306  TRAIN_2306     BRCA   0   WT    WT   WT                   WT    WT   \n",
       "2389  TRAIN_2389     COAD   0   WT    WT   WT                   WT    WT   \n",
       "2510  TRAIN_2510     LUAD   0   WT    WT   WT                   WT    WT   \n",
       "2746  TRAIN_2746     BRCA   0   WT    WT   WT                   WT    WT   \n",
       "2969  TRAIN_2969     BLCA   0   WT    WT   WT                   WT    WT   \n",
       "2984  TRAIN_2984     COAD   0   WT    WT    0  S2192N F1854F K376R    WT   \n",
       "3715  TRAIN_3715     UCEC   0   WT    WT   WT                   WT    WT   \n",
       "4523  TRAIN_4523     BLCA   0   WT    WT   WT                   WT    WT   \n",
       "5163  TRAIN_5163    KIPAN   0   WT    WT   WT                   WT    WT   \n",
       "5211  TRAIN_5211     KIRC   0   WT    WT   WT                   WT    WT   \n",
       "5703  TRAIN_5703     KIRC   0   WT    WT   WT                   WT    WT   \n",
       "5789  TRAIN_5789     SKCM   0   WT    WT   WT                   WT    WT   \n",
       "\n",
       "     ABCA3                 ABCA4  ... ZNF292 ZNF365 ZNF639 ZNF707   ZNFX1  \\\n",
       "120     WT                    WT  ...     WT     WT     WT     WT      WT   \n",
       "318     WT                    WT  ...     WT     WT     WT     WT      WT   \n",
       "669     WT                    WT  ...     WT     WT     WT     WT      WT   \n",
       "2136    WT                    WT  ...     WT      0     WT     WT      WT   \n",
       "2306    WT                    WT  ...     WT     WT     WT     WT      WT   \n",
       "2389    WT                    WT  ...     WT     WT     WT     WT      WT   \n",
       "2510    WT                    WT  ...     WT     WT     WT     WT      WT   \n",
       "2746    WT                    WT  ...     WT     WT     WT     WT      WT   \n",
       "2969    WT                    WT  ...     WT     WT     WT     WT      WT   \n",
       "2984    WT  V1698V E1295* S1071L  ...      0     WT     WT     WT      WT   \n",
       "3715    WT                    WT  ...     WT      0     WT     WT      WT   \n",
       "4523    WT                    WT  ...     WT     WT     WT     WT      WT   \n",
       "5163    WT                    WT  ...     WT     WT     WT     WT      WT   \n",
       "5211    WT                    WT  ...     WT     WT     WT     WT      WT   \n",
       "5703    WT                    WT  ...     WT     WT     WT     WT      WT   \n",
       "5789    WT                A2037V  ...     WT     WT     WT     WT  R1223*   \n",
       "\n",
       "     ZNRF4   ZPBP   ZW10 ZWINT    ZYX  \n",
       "120     WT     WT     WT    WT     WT  \n",
       "318     WT     WT     WT    WT     WT  \n",
       "669     WT     WT     WT    WT     WT  \n",
       "2136    WT     WT     WT    WT     WT  \n",
       "2306    WT     WT     WT    WT     WT  \n",
       "2389    WT     WT     WT    WT     WT  \n",
       "2510    WT  E291E     WT    WT     WT  \n",
       "2746    WT     WT     WT    WT     WT  \n",
       "2969    WT     WT     WT    WT     WT  \n",
       "2984    WT     WT     WT    WT     WT  \n",
       "3715    WT     WT     WT    WT     WT  \n",
       "4523    WT     WT     WT    WT     WT  \n",
       "5163    WT     WT     WT    WT     WT  \n",
       "5211    WT     WT     WT    WT     WT  \n",
       "5703    WT     WT     WT    WT     WT  \n",
       "5789    WT     WT  S150F    WT  E102K  \n",
       "\n",
       "[16 rows x 4227 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_processed3[train_processed3['A2M'] == '0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>A2M</th>\n",
       "      <th>AAAS</th>\n",
       "      <th>AADAT</th>\n",
       "      <th>ABAT</th>\n",
       "      <th>ABCA1</th>\n",
       "      <th>ABCA2</th>\n",
       "      <th>ABCA3</th>\n",
       "      <th>ABCA4</th>\n",
       "      <th>ABCA5</th>\n",
       "      <th>...</th>\n",
       "      <th>ZNF292</th>\n",
       "      <th>ZNF365</th>\n",
       "      <th>ZNF639</th>\n",
       "      <th>ZNF707</th>\n",
       "      <th>ZNFX1</th>\n",
       "      <th>ZNRF4</th>\n",
       "      <th>ZPBP</th>\n",
       "      <th>ZW10</th>\n",
       "      <th>ZWINT</th>\n",
       "      <th>ZYX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>TEST_1525</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>L317fs</td>\n",
       "      <td>A2200V A2230V</td>\n",
       "      <td>R20W</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>Q288Q</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>R992C</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1873</th>\n",
       "      <td>TEST_1873</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 4226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID A2M AAAS AADAT ABAT   ABCA1          ABCA2 ABCA3 ABCA4 ABCA5  \\\n",
       "1525  TEST_1525   0   WT    WT   WT  L317fs  A2200V A2230V  R20W    WT    WT   \n",
       "1873  TEST_1873   0   WT    WT   WT      WT             WT     0     0    WT   \n",
       "\n",
       "      ... ZNF292 ZNF365 ZNF639 ZNF707  ZNFX1 ZNRF4 ZPBP ZW10 ZWINT ZYX  \n",
       "1525  ...     WT  Q288Q     WT     WT  R992C     0   WT   WT    WT  WT  \n",
       "1873  ...     WT     WT      0     WT     WT     0   WT   WT    WT  WT  \n",
       "\n",
       "[2 rows x 4226 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_processed3[test_processed3['A2M'] == '0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### silent driver 적용 (51s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "silent_driver = pd.read_csv('silent_driver.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "silent_driver['Gene name'] = silent_driver['Gene name'].str.split('_').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes = train.drop(columns=['ID','SUBCLASS']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "silent_driver = silent_driver[silent_driver['Gene name'].isin(yes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "silent_driver_dict = silent_driver.groupby('Gene name')['Mutation'].apply(lambda x: np.array(x)).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_silent_driver(train, silent_driver_dict):\n",
    "    # 유전자 열만 추출 ('ID', 'SUBCLASS' 제외)\n",
    "    gene_columns = [col for col in train.columns if col not in ['ID', 'SUBCLASS']]\n",
    "    \n",
    "    # 각 유전자 열에 대해 처리\n",
    "    for gene in gene_columns:\n",
    "        if gene in silent_driver_dict:  # misense_driver_dict에 해당 유전자가 존재하는지 확인\n",
    "            # 해당 유전자의 돌연변이 리스트 가져오기\n",
    "            mutation_list = silent_driver_dict[gene]\n",
    "            \n",
    "            # 해당 열에 대해 값이 돌연변이 리스트에 있는지 확인하고 있으면 30으로 대체\n",
    "            #train[gene] = train[gene].apply(lambda x: 0 if x in mutation_list else x )\n",
    "            train[gene] = train[gene].apply(lambda x: str(30) if not isinstance(x, (int, float)) and x in mutation_list else x)\n",
    "\n",
    "    \n",
    "    return train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed4 = update_silent_driver(train_processed3,silent_driver_dict)\n",
    "test_processed4 = update_silent_driver(test_processed3,silent_driver_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SUBCLASS</th>\n",
       "      <th>A2M</th>\n",
       "      <th>AAAS</th>\n",
       "      <th>AADAT</th>\n",
       "      <th>ABAT</th>\n",
       "      <th>ABCA1</th>\n",
       "      <th>ABCA2</th>\n",
       "      <th>ABCA3</th>\n",
       "      <th>ABCA4</th>\n",
       "      <th>...</th>\n",
       "      <th>ZNF292</th>\n",
       "      <th>ZNF365</th>\n",
       "      <th>ZNF639</th>\n",
       "      <th>ZNF707</th>\n",
       "      <th>ZNFX1</th>\n",
       "      <th>ZNRF4</th>\n",
       "      <th>ZPBP</th>\n",
       "      <th>ZW10</th>\n",
       "      <th>ZWINT</th>\n",
       "      <th>ZYX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>TRAIN_0594</td>\n",
       "      <td>CESC</td>\n",
       "      <td>30</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>TRAIN_1758</td>\n",
       "      <td>STES</td>\n",
       "      <td>30</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>T128T</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>M456T</td>\n",
       "      <td>30</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>TRAIN_1802</td>\n",
       "      <td>LUAD</td>\n",
       "      <td>30</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>TRAIN_1818</td>\n",
       "      <td>COAD</td>\n",
       "      <td>30</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>TRAIN_2477</td>\n",
       "      <td>BRCA</td>\n",
       "      <td>30</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>R162C</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3729</th>\n",
       "      <td>TRAIN_3729</td>\n",
       "      <td>COAD</td>\n",
       "      <td>30</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 4227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID SUBCLASS A2M AAAS AADAT ABAT ABCA1 ABCA2 ABCA3 ABCA4  ...  \\\n",
       "594   TRAIN_0594     CESC  30   WT    WT   WT    WT    WT    WT    WT  ...   \n",
       "1758  TRAIN_1758     STES  30   WT    WT   WT    WT    WT    WT    WT  ...   \n",
       "1802  TRAIN_1802     LUAD  30   WT    WT   WT    WT    WT    WT    WT  ...   \n",
       "1818  TRAIN_1818     COAD  30   WT    WT   WT    WT    WT    WT    WT  ...   \n",
       "2477  TRAIN_2477     BRCA  30   WT    WT   WT    WT    WT    WT    WT  ...   \n",
       "3729  TRAIN_3729     COAD  30   WT    WT   WT    WT    WT    WT    WT  ...   \n",
       "\n",
       "     ZNF292 ZNF365 ZNF639 ZNF707  ZNFX1  ZNRF4 ZPBP ZW10 ZWINT ZYX  \n",
       "594      WT     WT     WT     WT     WT     WT   WT   WT    WT  WT  \n",
       "1758     WT  T128T     WT     WT  M456T     30   WT   WT    WT  WT  \n",
       "1802     WT     WT     WT     WT     WT     WT   WT   WT    WT  WT  \n",
       "1818      0     WT     WT     WT     WT     WT   WT   WT    WT  WT  \n",
       "2477     WT     WT     WT     WT     WT  R162C   WT   WT    WT  WT  \n",
       "3729     WT     WT     WT     WT     WT     WT   WT   WT    WT  WT  \n",
       "\n",
       "[6 rows x 4227 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_processed4[train_processed4['A2M'] == '30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>A2M</th>\n",
       "      <th>AAAS</th>\n",
       "      <th>AADAT</th>\n",
       "      <th>ABAT</th>\n",
       "      <th>ABCA1</th>\n",
       "      <th>ABCA2</th>\n",
       "      <th>ABCA3</th>\n",
       "      <th>ABCA4</th>\n",
       "      <th>ABCA5</th>\n",
       "      <th>...</th>\n",
       "      <th>ZNF292</th>\n",
       "      <th>ZNF365</th>\n",
       "      <th>ZNF639</th>\n",
       "      <th>ZNF707</th>\n",
       "      <th>ZNFX1</th>\n",
       "      <th>ZNRF4</th>\n",
       "      <th>ZPBP</th>\n",
       "      <th>ZW10</th>\n",
       "      <th>ZWINT</th>\n",
       "      <th>ZYX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2370</th>\n",
       "      <td>TEST_2370</td>\n",
       "      <td>30</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>V1179I</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 4226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID A2M AAAS AADAT ABAT ABCA1 ABCA2 ABCA3 ABCA4 ABCA5  ... ZNF292  \\\n",
       "2370  TEST_2370  30   WT    WT   WT    WT    WT    WT    WT    WT  ...     WT   \n",
       "\n",
       "     ZNF365 ZNF639 ZNF707   ZNFX1 ZNRF4 ZPBP ZW10 ZWINT ZYX  \n",
       "2370     WT     WT     WT  V1179I    WT   WT   WT    WT  WT  \n",
       "\n",
       "[1 rows x 4226 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_processed4[test_processed4['A2M'] == '30']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### silent passenger 적용 (2m 42s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "silent_passenger = pd.read_csv('silent_passenger.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "silent_passenger['Gene name'] = silent_passenger['Gene name'].str.split('_').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes = train.drop(columns=['ID','SUBCLASS']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "silent_passenger = silent_passenger[silent_passenger['Gene name'].isin(yes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "silent_passenger_dict = silent_passenger.groupby('Gene name')['Mutation'].apply(lambda x: np.array(x)).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_silent_passenger(train, silent_passenger_dict):\n",
    "    # 유전자 열만 추출 ('ID', 'SUBCLASS' 제외)\n",
    "    gene_columns = [col for col in train.columns if col not in ['ID', 'SUBCLASS']]\n",
    "    \n",
    "    # 각 유전자 열에 대해 처리\n",
    "    for gene in gene_columns:\n",
    "        if gene in silent_passenger_dict:  # misense_driver_dict에 해당 유전자가 존재하는지 확인\n",
    "            # 해당 유전자의 돌연변이 리스트 가져오기\n",
    "            mutation_list = silent_passenger_dict[gene]\n",
    "            \n",
    "            # 해당 열에 대해 값이 돌연변이 리스트에 있는지 확인하고 있으면 30으로 대체\n",
    "            #train[gene] = train[gene].apply(lambda x: 0 if x in mutation_list else x )\n",
    "            train[gene] = train[gene].apply(lambda x: str(0) if not isinstance(x, (int, float)) and x in mutation_list else x)\n",
    "\n",
    "    \n",
    "    return train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed5 = update_silent_passenger(train_processed4,silent_passenger_dict)\n",
    "test_processed5 = update_silent_passenger(test_processed4,silent_passenger_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SUBCLASS</th>\n",
       "      <th>A2M</th>\n",
       "      <th>AAAS</th>\n",
       "      <th>AADAT</th>\n",
       "      <th>ABAT</th>\n",
       "      <th>ABCA1</th>\n",
       "      <th>ABCA2</th>\n",
       "      <th>ABCA3</th>\n",
       "      <th>ABCA4</th>\n",
       "      <th>...</th>\n",
       "      <th>ZNF292</th>\n",
       "      <th>ZNF365</th>\n",
       "      <th>ZNF639</th>\n",
       "      <th>ZNF707</th>\n",
       "      <th>ZNFX1</th>\n",
       "      <th>ZNRF4</th>\n",
       "      <th>ZPBP</th>\n",
       "      <th>ZW10</th>\n",
       "      <th>ZWINT</th>\n",
       "      <th>ZYX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>TRAIN_0120</td>\n",
       "      <td>KIPAN</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>TRAIN_0318</td>\n",
       "      <td>BLCA</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>TRAIN_0669</td>\n",
       "      <td>BLCA</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>TRAIN_1502</td>\n",
       "      <td>COAD</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>V1774V T311T</td>\n",
       "      <td>...</td>\n",
       "      <td>K162T S664S A779V T1526M L1806V R2115*</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>Q1572Q H730Q I688I</td>\n",
       "      <td>WT</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>TRAIN_1606</td>\n",
       "      <td>BRCA</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2136</th>\n",
       "      <td>TRAIN_2136</td>\n",
       "      <td>LUAD</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306</th>\n",
       "      <td>TRAIN_2306</td>\n",
       "      <td>BRCA</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2389</th>\n",
       "      <td>TRAIN_2389</td>\n",
       "      <td>COAD</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2510</th>\n",
       "      <td>TRAIN_2510</td>\n",
       "      <td>LUAD</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>TRAIN_2746</td>\n",
       "      <td>BRCA</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2962</th>\n",
       "      <td>TRAIN_2962</td>\n",
       "      <td>BLCA</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2969</th>\n",
       "      <td>TRAIN_2969</td>\n",
       "      <td>BLCA</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>TRAIN_2984</td>\n",
       "      <td>COAD</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>0</td>\n",
       "      <td>S2192N F1854F K376R</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>V1698V E1295* S1071L</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3153</th>\n",
       "      <td>TRAIN_3153</td>\n",
       "      <td>UCEC</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3715</th>\n",
       "      <td>TRAIN_3715</td>\n",
       "      <td>UCEC</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4005</th>\n",
       "      <td>TRAIN_4005</td>\n",
       "      <td>BRCA</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4146</th>\n",
       "      <td>TRAIN_4146</td>\n",
       "      <td>COAD</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4523</th>\n",
       "      <td>TRAIN_4523</td>\n",
       "      <td>BLCA</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4900</th>\n",
       "      <td>TRAIN_4900</td>\n",
       "      <td>COAD</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5163</th>\n",
       "      <td>TRAIN_5163</td>\n",
       "      <td>KIPAN</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5173</th>\n",
       "      <td>TRAIN_5173</td>\n",
       "      <td>UCEC</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>R533W</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5211</th>\n",
       "      <td>TRAIN_5211</td>\n",
       "      <td>KIRC</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5703</th>\n",
       "      <td>TRAIN_5703</td>\n",
       "      <td>KIRC</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5789</th>\n",
       "      <td>TRAIN_5789</td>\n",
       "      <td>SKCM</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>A2037V</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>R1223*</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>S150F</td>\n",
       "      <td>WT</td>\n",
       "      <td>E102K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6156</th>\n",
       "      <td>TRAIN_6156</td>\n",
       "      <td>COAD</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>0</td>\n",
       "      <td>C641*</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>D186Y</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows × 4227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID SUBCLASS A2M AAAS AADAT ABAT                ABCA1 ABCA2  \\\n",
       "120   TRAIN_0120    KIPAN   0   WT    WT   WT                   WT    WT   \n",
       "318   TRAIN_0318     BLCA   0   WT    WT   WT                   WT    WT   \n",
       "669   TRAIN_0669     BLCA   0   WT    WT   WT                   WT    WT   \n",
       "1502  TRAIN_1502     COAD   0   WT    WT    0                   WT    WT   \n",
       "1606  TRAIN_1606     BRCA   0   WT    WT   WT                   WT    WT   \n",
       "2136  TRAIN_2136     LUAD   0   WT    WT   WT                    0    WT   \n",
       "2306  TRAIN_2306     BRCA   0   WT    WT   WT                   WT    WT   \n",
       "2389  TRAIN_2389     COAD   0   WT    WT   WT                   WT    WT   \n",
       "2510  TRAIN_2510     LUAD   0   WT    WT   WT                   WT    WT   \n",
       "2746  TRAIN_2746     BRCA   0   WT    WT   WT                   WT    WT   \n",
       "2962  TRAIN_2962     BLCA   0   WT    WT   WT                   WT    WT   \n",
       "2969  TRAIN_2969     BLCA   0   WT    WT   WT                   WT    WT   \n",
       "2984  TRAIN_2984     COAD   0   WT    WT    0  S2192N F1854F K376R    WT   \n",
       "3153  TRAIN_3153     UCEC   0   WT    WT   WT                   WT    WT   \n",
       "3715  TRAIN_3715     UCEC   0   WT    WT   WT                   WT    WT   \n",
       "4005  TRAIN_4005     BRCA   0   WT    WT   WT                   WT    WT   \n",
       "4146  TRAIN_4146     COAD   0   WT    WT   WT                   WT    WT   \n",
       "4523  TRAIN_4523     BLCA   0   WT    WT   WT                   WT    WT   \n",
       "4900  TRAIN_4900     COAD   0   WT    WT   WT                    0    WT   \n",
       "5163  TRAIN_5163    KIPAN   0   WT    WT   WT                   WT    WT   \n",
       "5173  TRAIN_5173     UCEC   0   WT    WT   WT                   WT    WT   \n",
       "5211  TRAIN_5211     KIRC   0   WT    WT   WT                   WT    WT   \n",
       "5703  TRAIN_5703     KIRC   0   WT    WT   WT                   WT    WT   \n",
       "5789  TRAIN_5789     SKCM   0   WT    WT   WT                   WT    WT   \n",
       "6156  TRAIN_6156     COAD   0   WT    WT   WT                    0    WT   \n",
       "\n",
       "     ABCA3                 ABCA4  ...                                  ZNF292  \\\n",
       "120     WT                    WT  ...                                      WT   \n",
       "318     WT                    WT  ...                                      WT   \n",
       "669     WT                    WT  ...                                      WT   \n",
       "1502    WT          V1774V T311T  ...  K162T S664S A779V T1526M L1806V R2115*   \n",
       "1606    WT                    WT  ...                                      WT   \n",
       "2136    WT                    WT  ...                                      WT   \n",
       "2306    WT                    WT  ...                                      WT   \n",
       "2389    WT                    WT  ...                                      WT   \n",
       "2510    WT                    WT  ...                                      WT   \n",
       "2746    WT                    WT  ...                                      WT   \n",
       "2962    WT                    WT  ...                                      WT   \n",
       "2969    WT                    WT  ...                                      WT   \n",
       "2984    WT  V1698V E1295* S1071L  ...                                       0   \n",
       "3153    WT                    WT  ...                                      WT   \n",
       "3715    WT                    WT  ...                                      WT   \n",
       "4005    WT                    WT  ...                                      WT   \n",
       "4146    WT                    WT  ...                                      WT   \n",
       "4523    WT                    WT  ...                                      WT   \n",
       "4900    WT                    WT  ...                                       0   \n",
       "5163    WT                    WT  ...                                      WT   \n",
       "5173    WT                    WT  ...                                   R533W   \n",
       "5211    WT                    WT  ...                                      WT   \n",
       "5703    WT                    WT  ...                                      WT   \n",
       "5789    WT                A2037V  ...                                      WT   \n",
       "6156     0                 C641*  ...                                      WT   \n",
       "\n",
       "     ZNF365 ZNF639 ZNF707               ZNFX1 ZNRF4 ZPBP   ZW10  ZWINT    ZYX  \n",
       "120      WT     WT     WT                  WT    WT   WT     WT     WT     WT  \n",
       "318      WT     WT     WT                  WT    WT   WT     WT     WT     WT  \n",
       "669      WT     WT     WT                  WT    WT   WT     WT     WT     WT  \n",
       "1502     WT     WT     WT  Q1572Q H730Q I688I    WT    0     WT     WT     WT  \n",
       "1606     WT     WT     WT                  WT    WT   WT     WT     WT     WT  \n",
       "2136      0     WT     WT                  WT    WT   WT     WT     WT     WT  \n",
       "2306     WT     WT     WT                  WT    WT   WT     WT     WT     WT  \n",
       "2389     WT     WT     WT                  WT    WT   WT     WT     WT     WT  \n",
       "2510     WT     WT     WT                  WT    WT    0     WT     WT     WT  \n",
       "2746     WT     WT     WT                  WT    WT   WT     WT     WT     WT  \n",
       "2962     WT     WT     WT                  WT    WT   WT     WT     WT     WT  \n",
       "2969     WT     WT     WT                  WT    WT   WT     WT     WT     WT  \n",
       "2984     WT     WT     WT                  WT    WT   WT     WT     WT     WT  \n",
       "3153     WT     WT     WT                  WT    WT   WT     WT     WT     WT  \n",
       "3715      0     WT     WT                  WT    WT   WT     WT     WT     WT  \n",
       "4005     WT     WT     WT                  WT    WT   WT     WT     WT     WT  \n",
       "4146     WT     WT     WT                  WT    WT   WT     WT     WT     WT  \n",
       "4523     WT     WT     WT                  WT    WT   WT     WT     WT     WT  \n",
       "4900     WT     WT     WT                  WT    WT   WT     WT     WT     WT  \n",
       "5163     WT     WT     WT                  WT    WT   WT     WT     WT     WT  \n",
       "5173     WT     WT     WT                  WT    WT   WT     WT     WT     WT  \n",
       "5211     WT     WT     WT                  WT    WT   WT     WT     WT     WT  \n",
       "5703     WT     WT     WT                  WT    WT   WT     WT     WT     WT  \n",
       "5789     WT     WT     WT              R1223*    WT   WT  S150F     WT  E102K  \n",
       "6156     WT     WT     WT                   0    WT   WT     WT  D186Y     WT  \n",
       "\n",
       "[25 rows x 4227 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_processed5[train_processed5['A2M'] == '0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>A2M</th>\n",
       "      <th>AAAS</th>\n",
       "      <th>AADAT</th>\n",
       "      <th>ABAT</th>\n",
       "      <th>ABCA1</th>\n",
       "      <th>ABCA2</th>\n",
       "      <th>ABCA3</th>\n",
       "      <th>ABCA4</th>\n",
       "      <th>ABCA5</th>\n",
       "      <th>...</th>\n",
       "      <th>ZNF292</th>\n",
       "      <th>ZNF365</th>\n",
       "      <th>ZNF639</th>\n",
       "      <th>ZNF707</th>\n",
       "      <th>ZNFX1</th>\n",
       "      <th>ZNRF4</th>\n",
       "      <th>ZPBP</th>\n",
       "      <th>ZW10</th>\n",
       "      <th>ZWINT</th>\n",
       "      <th>ZYX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>TEST_1337</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>K1345*</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>A430E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>TEST_1525</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>L317fs</td>\n",
       "      <td>A2200V A2230V</td>\n",
       "      <td>R20W</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>Q288Q</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>R992C</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1873</th>\n",
       "      <td>TEST_1873</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2214</th>\n",
       "      <td>TEST_2214</td>\n",
       "      <td>0</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 4226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID A2M AAAS AADAT ABAT   ABCA1          ABCA2 ABCA3 ABCA4 ABCA5  \\\n",
       "1337  TEST_1337   0   WT    WT   WT      WT             WT    WT    WT    WT   \n",
       "1525  TEST_1525   0   WT    WT   WT  L317fs  A2200V A2230V  R20W    WT    WT   \n",
       "1873  TEST_1873   0   WT    WT   WT      WT             WT     0     0    WT   \n",
       "2214  TEST_2214   0   WT    WT   WT      WT             WT    WT    WT    WT   \n",
       "\n",
       "      ...  ZNF292 ZNF365 ZNF639 ZNF707  ZNFX1 ZNRF4 ZPBP ZW10 ZWINT    ZYX  \n",
       "1337  ...  K1345*     WT     WT     WT     WT    WT   WT   WT    WT  A430E  \n",
       "1525  ...      WT  Q288Q     WT     WT  R992C     0   WT   WT    WT     WT  \n",
       "1873  ...      WT     WT      0     WT     WT     0   WT   WT    WT     WT  \n",
       "2214  ...      WT     WT     WT     WT     WT    WT   WT   WT    WT     WT  \n",
       "\n",
       "[4 rows x 4226 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_processed5[test_processed5['A2M'] == '0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### amino acid 함수 정의 + train,test set 적용 (1m 26s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aminoacid version3\n",
    "# 변이 유형을 분류하는 함수 정의\n",
    "import pandas as pd\n",
    "import re\n",
    "amino_acid_properties = {\n",
    "    'A': 'nonpolar',    # Alanine\n",
    "    'R': 'positive',    # Arginine\n",
    "    'N': 'polar',       # Asparagine\n",
    "    'D': 'negative',    # Aspartic Acid\n",
    "    'C': 'polar',       # Cysteine\n",
    "    'Q': 'polar',       # Glutamine\n",
    "    'E': 'negative',    # Glutamic Acid\n",
    "    'G': 'nonpolar',    # Glycine\n",
    "    'H': 'positive',    # Histidine\n",
    "    'I': 'nonpolar',    # Isoleucine\n",
    "    'L': 'nonpolar',    # Leucine\n",
    "    'K': 'positive',    # Lysine\n",
    "    'M': 'nonpolar',    # Methionine\n",
    "    'F': 'aromatic',    # Phenylalanine\n",
    "    'P': 'nonpolar',    # Proline\n",
    "    'S': 'polar',       # Serine\n",
    "    'T': 'polar',       # Threonine\n",
    "    'W': 'aromatic',    # Tryptophan\n",
    "    'Y': 'aromatic',    # Tyrosine\n",
    "    'V': 'nonpolar',    # Valine\n",
    "}\n",
    "\n",
    "def classify_mutation(mutation):\n",
    "    # 결측치 처리\n",
    "    if pd.isnull(mutation):\n",
    "        return None  # 또는 특정 코드로 지정 가능\n",
    "\n",
    "    # 숫자인 경우 또는 숫자로 변환 가능한 경우 그대로 반환\n",
    "    try:\n",
    "        mutation = float(mutation)  # 숫자로 변환 시도\n",
    "        return int(mutation) if mutation.is_integer() else mutation  # 정수형이면 int, 실수형이면 그대로 반환\n",
    "    except ValueError:\n",
    "        pass  # 숫자가 아닌 경우 문자열 처리로 넘어감\n",
    "\n",
    "    mutation = str(mutation).strip()\n",
    "\n",
    "    # WT 체크\n",
    "    if mutation == 'WT':\n",
    "        return 0  # WT (Wild Type)\n",
    "\n",
    "    # 프레임시프트 돌연변이 체크 ('fs' 포함)\n",
    "    if 'fs' in mutation:\n",
    "        return 30  # 프레임시프트 돌연변이\n",
    "\n",
    "    # 중단 돌연변이 체크 ('*' 포함)\n",
    "    if '*' in mutation:\n",
    "        return 30  # 중단 돌연변이\n",
    "\n",
    "    # 삭제 돌연변이 체크 ('del' 포함)\n",
    "    if 'del' in mutation:\n",
    "        return 30  # 삭제 돌연변이 (Deletion mutation)\n",
    "\n",
    "    # 단일 아미노산 변이 패턴 매칭 (예: 'R496Q', 'L1700L')\n",
    "    match = re.match(r'^([A-Z])(\\d*)([A-Z])$', mutation)\n",
    "    if match:\n",
    "        from_aa = match.group(1)  # 원래 아미노산\n",
    "        position = match.group(2) # 위치 (사용하지 않음)\n",
    "        to_aa = match.group(3)    # 변이된 아미노산\n",
    "\n",
    "        # 침묵 돌연변이 체크 (아미노산이 동일한 경우)\n",
    "        if from_aa == to_aa:\n",
    "            return 0 # 침묵 돌연변이\n",
    "\n",
    "        # 아미노산 성질 가져오기\n",
    "        from_property = amino_acid_properties.get(from_aa)\n",
    "        to_property = amino_acid_properties.get(to_aa)\n",
    "\n",
    "        # 아미노산 코드가 유효한지 확인\n",
    "        if from_property is None or to_property is None:\n",
    "            return 7  # 알 수 없는 아미노산 코드\n",
    "\n",
    "        # 보존적 돌연변이 체크 (아미노산 성질이 동일한 경우)\n",
    "        if from_property == to_property:\n",
    "            return 2  # 보존적 돌연변이\n",
    "        else:\n",
    "            return 3  # 비보존적 돌연변이\n",
    "    else:\n",
    "        # 패턴 매칭 실패한 경우\n",
    "        return 7  # 매칭 실패한 경우 7 반환\n",
    "\n",
    "# 다중 치환을 처리하는 함수 정의\n",
    "def classify_multiple_mutations(mutation_string):\n",
    "    # 결측치 처리\n",
    "    if pd.isnull(mutation_string):\n",
    "        return None  # 또는 특정 코드로 지정 가능\n",
    "\n",
    "    # 변이 문자열을 공백으로 분리\n",
    "    mutations = set(str(mutation_string).strip().split())\n",
    "\n",
    "    labels = []\n",
    "    for mutation in mutations:\n",
    "        # 숫자인 경우 또는 숫자로 변환 가능한 경우 그대로 유지\n",
    "        try:\n",
    "            mutation = float(mutation)  # 숫자로 변환 시도\n",
    "            mutation = int(mutation) if mutation.is_integer() else mutation  # 정수형이면 int, 실수형이면 그대로 유지\n",
    "            labels.append(mutation)\n",
    "        except ValueError:\n",
    "            # 숫자가 아닌 경우 기존 로직 사용\n",
    "            label = classify_mutation(mutation)\n",
    "            if label is not None:\n",
    "                labels.append(label)\n",
    "\n",
    "    if labels:\n",
    "        # 합계 반환\n",
    "        return sum(labels)\n",
    "    else:\n",
    "        return None  # 또는 특정 코드로 지정 가능\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제외할 열 목록 (예시로 'ID'와 'SUBCLASS'를 제외)\n",
    "exclude_cols = ['ID', 'SUBCLASS']\n",
    "\n",
    "# 변이 데이터가 있는 열 목록\n",
    "mutation_cols = [col for col in train_processed5.columns if col not in exclude_cols]\n",
    "\n",
    "# 각 열에 함수 적용\n",
    "for col in mutation_cols:\n",
    "    train_processed5[col] = train_processed5[col].apply(classify_multiple_mutations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제외할 열 목록 (예시로 'ID'와 'SUBCLASS'를 제외)\n",
    "exclude_cols = ['ID', 'SUBCLASS']\n",
    "\n",
    "# 변이 데이터가 있는 열 목록\n",
    "mutation_cols = [col for col in test_processed5.columns if col not in exclude_cols]\n",
    "\n",
    "# 각 열에 함수 적용\n",
    "for col in mutation_cols:\n",
    "    test_processed5[col] = test_processed5[col].apply(classify_multiple_mutations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV 저장 & 불러오기\n",
    "- 함수 적용 시간이 오래걸리기때문에 여기까지 trian을 csv로 저장 후 불러내기 해서 사용\n",
    "- 저장한 train파일에 컬럼(유전자) 수는 원래 유전자수(4865)에서 모든 행이 'WT'이 제거됨 (4226열)\n",
    "- 저장된 파일은 전처리가 끝난 상태 -> 모델만 수정해가면서 train,test 불러와서 반복해서 돌리기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4개의 csv파일함수적용 후 'PS_mapping_ver3.csv'로 저장하기 ( 최초 1회만 실행)\n",
    "train_processed5.to_csv('PS_mapping_ver3.csv')\n",
    "test_processed5.to_csv('test_wtcut.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두번째부터 여기부터 실행하기 train,test 는 전처리가 끝났음, 바로 모델에 학습시키면 됨\n",
    "import pandas as pd\n",
    "train = pd.read_csv('./open/train_preprocessed.csv')\n",
    "train = train.iloc[:,1:]\n",
    "test = pd.read_csv('./open/test_preprocessed.csv')\n",
    "test = test.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_subclass = LabelEncoder()\n",
    "train['SUBCLASS'] = le_subclass.fit_transform(train['SUBCLASS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- aminoacid version 3 ( 공통 'WT' 제거 했을 때)\n",
    "- Train Accuracy: 74.64%\n",
    "- Test Accuracy: 36.66%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SUBCLASS</th>\n",
       "      <th>A2M</th>\n",
       "      <th>AAAS</th>\n",
       "      <th>AADAT</th>\n",
       "      <th>ABAT</th>\n",
       "      <th>ABCA1</th>\n",
       "      <th>ABCA2</th>\n",
       "      <th>ABCA3</th>\n",
       "      <th>ABCA4</th>\n",
       "      <th>...</th>\n",
       "      <th>ZNF292</th>\n",
       "      <th>ZNF365</th>\n",
       "      <th>ZNF639</th>\n",
       "      <th>ZNF707</th>\n",
       "      <th>ZNFX1</th>\n",
       "      <th>ZNRF4</th>\n",
       "      <th>ZPBP</th>\n",
       "      <th>ZW10</th>\n",
       "      <th>ZWINT</th>\n",
       "      <th>ZYX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_0000</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_0001</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_0002</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_0003</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_0004</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  SUBCLASS  A2M  AAAS  AADAT  ABAT  ABCA1  ABCA2  ABCA3  ABCA4  \\\n",
       "0  TRAIN_0000         8    0     0      0     0      0      0      0      0   \n",
       "1  TRAIN_0001        19    0     0      0     0      0      0      0      0   \n",
       "2  TRAIN_0002        20    0     0      0     0      0      0      0      0   \n",
       "3  TRAIN_0003         9    0     0      0     0      0      0      0      0   \n",
       "4  TRAIN_0004         6    0     0      0     0      0      0      0      0   \n",
       "\n",
       "   ...  ZNF292  ZNF365  ZNF639  ZNF707  ZNFX1  ZNRF4  ZPBP  ZW10  ZWINT  ZYX  \n",
       "0  ...       0       0       0       0      0      0     0     0      0    0  \n",
       "1  ...       0       0       0       0      0      0     0     0      0    0  \n",
       "2  ...       0       0       0       0      0      0     0     0      0    0  \n",
       "3  ...       0       0       0       0      0      0     0     0      0    0  \n",
       "4  ...       0       0       0       0      0      0     0     0      0    0  \n",
       "\n",
       "[5 rows x 4227 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>A2M</th>\n",
       "      <th>AAAS</th>\n",
       "      <th>AADAT</th>\n",
       "      <th>ABAT</th>\n",
       "      <th>ABCA1</th>\n",
       "      <th>ABCA2</th>\n",
       "      <th>ABCA3</th>\n",
       "      <th>ABCA4</th>\n",
       "      <th>ABCA5</th>\n",
       "      <th>...</th>\n",
       "      <th>ZNF292</th>\n",
       "      <th>ZNF365</th>\n",
       "      <th>ZNF639</th>\n",
       "      <th>ZNF707</th>\n",
       "      <th>ZNFX1</th>\n",
       "      <th>ZNRF4</th>\n",
       "      <th>ZPBP</th>\n",
       "      <th>ZW10</th>\n",
       "      <th>ZWINT</th>\n",
       "      <th>ZYX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_0001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_0002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_0003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_0004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  A2M  AAAS  AADAT  ABAT  ABCA1  ABCA2  ABCA3  ABCA4  ABCA5  ...  \\\n",
       "0  TEST_0000    0     0      0     0      0      0      0      0      0  ...   \n",
       "1  TEST_0001    0     0      0     0      3      0      0      0      0  ...   \n",
       "2  TEST_0002    0     0      0     0      0      0      0      0      0  ...   \n",
       "3  TEST_0003    0     0      0     0      0      0      0      0      0  ...   \n",
       "4  TEST_0004    0     0      0     0      0      0      0      0      0  ...   \n",
       "\n",
       "   ZNF292  ZNF365  ZNF639  ZNF707  ZNFX1  ZNRF4  ZPBP  ZW10  ZWINT  ZYX  \n",
       "0       0       0       0       0      0      0     0     0      0    0  \n",
       "1       0       0       0       0      0     30     0     0      0    0  \n",
       "2       0       0       0       0      0      0     0     0      0    0  \n",
       "3       0       0       0       0      0      0     0     0      0    0  \n",
       "4       0       0       0       0      0      0     0     0      0    0  \n",
       "\n",
       "[5 rows x 4226 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 준비\n",
    "X = train.drop(columns=['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ag\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20241009_172807\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.15\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          16\n",
      "Memory Avail:       22.13 GB / 31.64 GB (70.0%)\n",
      "Disk Space Avail:   352.40 GB / 476.00 GB (74.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=4, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 6300s of the 25200s of remaining time (25%).\n",
      "2024-10-10 02:28:08,270\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ag\\lib\\site-packages\\autogluon\\tabular\\predictor\\predictor.py:1242: UserWarning: Failed to use ray for memory safe fits. Falling back to normal fit. Error: ValueError('ray==2.31.0 detected. 2.10.0 <= ray < 2.11.0 is required. You can use pip to install certain version of ray `pip install ray==2.10.0` ')\n",
      "  stacked_overfitting = self._sub_fit_memory_save_wrapper(\n",
      "\t\tContext path: \"AutogluonModels\\ag-20241009_172807\\ds_sub_fit\\sub_fit_ho\"\n",
      "Running DyStack sub-fit ...\n",
      "Beginning AutoGluon training ... Time limit = 6299s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20241009_172807\\ds_sub_fit\\sub_fit_ho\"\n",
      "Train Data Rows:    5512\n",
      "Train Data Columns: 4225\n",
      "Label Column:       SUBCLASS\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 26\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    22277.63 MB\n",
      "\tTrain Data (Original)  Memory Usage: 177.67 MB (0.8% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 100 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 9): ['AP2S1', 'CEBPD', 'CTF1', 'FKBP1B', 'GADD45A', 'LSM2', 'MT1E', 'PCSK1N', 'TMEM158']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 157): ['ARHGDIG', 'ARL4A', 'ARL6IP1', 'ARPC3', 'ATOX1', 'ATP6V0C', 'BET1', 'BST2', 'CBR3', 'CCL11', 'CCL20', 'CCNG2', 'CD302', 'CD40', 'CDA', 'CDC42SE2', 'CDKN2B', 'CHCHD10', 'CKS1B', 'CKS2', 'CLDN3', 'CLIC3', 'CLNS1A', 'CNN3', 'COX17', 'COX6A2', 'COX7C', 'CRB3', 'CRIP2', 'CTNS', 'CXCL10', 'CXCL11', 'DAP', 'DCTPP1', 'DCXR', 'DDT', 'DUSP1', 'DUSP3', 'DUT', 'DYNLL2', 'EFNA1', 'EIF4EBP1', 'ERH', 'FCER1G', 'FGF2', 'FGF22', 'FKBP2', 'FXN', 'GABARAPL1', 'GABARAPL2', 'GLIPR2', 'GLRX', 'GLRX5', 'GNGT1', 'GPR3', 'GPX3', 'GRHPR', 'GTF2H5', 'HBQ1', 'HBZ', 'HINT1', 'HSPA1A', 'HSPE1', 'IFI27', 'IFITM2', 'IL9', 'IMP3', 'ISG15', 'ITPA', 'KLF1', 'LEAP2', 'MAFF', 'MAL2', 'MRPL11', 'MRPL34', 'MRPS15', 'MT3', 'MXD3', 'MYL4', 'NDUFA4', 'NDUFB1', 'NDUFB8', 'NDUFC1', 'NDUFS6', 'NME3', 'NME4', 'NT5C', 'NTHL1', 'NUPR1', 'NXT1', 'OSTC', 'OXT', 'PCBD1', 'PDAP1', 'PDE6G', 'PDGFA', 'PEMT', 'PEX11G', 'PEX26', 'PFN1', 'PHLDA3', 'PMP22', 'POLE4', 'POLR2J', 'POLR3G', 'POLR3GL', 'PPIA', 'PRDX5', 'PRM2', 'PSME1', 'PTGES3', 'PXMP2', 'RCAN1', 'RHOF', 'RPA3', 'RPL14', 'RPL39', 'RPS10', 'RPS12', 'RPS14', 'S100A13', 'SCGB1A1', 'SDHB', 'SEC11A', 'SERTAD1', 'SH3BP5', 'SHE', 'SIT1', 'SKP1', 'SLC25A28', 'SLC31A2', 'SLC37A4', 'SNCB', 'SNRPD1', 'SNRPG', 'SOCS3', 'SOD1', 'SOD3', 'SRM', 'SRP14', 'SRSF10', 'SUCLA2', 'TAF12', 'TAX1BP3', 'TFF3', 'TIMP2', 'TNNC2', 'TNNI1', 'TOR1B', 'TPRKB', 'TSPO', 'TSPO2', 'UBE2C', 'UQCRH', 'VAMP3', 'VAMP8', 'YPEL1']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('int', []) : 157 | ['ARHGDIG', 'ARL4A', 'ARL6IP1', 'ARPC3', 'ATOX1', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', []) : 4059 | ['A2M', 'AAAS', 'AADAT', 'ABAT', 'ABCA1', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('int', [])       : 4008 | ['A2M', 'AAAS', 'AADAT', 'ABAT', 'ABCA1', ...]\n",
      "\t\t('int', ['bool']) :   51 | ['ARHGDIA', 'ATP6V0E1', 'CCL2', 'CCL22', 'CFD', ...]\n",
      "\t30.4s = Fit runtime\n",
      "\t4059 features in original data used to generate 4059 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 168.82 MB (0.8% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 31.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 5 stack levels (L1 to L5) ...\n",
      "Fitting 110 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 1671.01s of the 6267.78s of remaining time.\n",
      "\t0.2308\t = Validation score   (accuracy)\n",
      "\t0.95s\t = Training   runtime\n",
      "\t1.63s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 1663.31s of the 6260.08s of remaining time.\n",
      "\t0.2201\t = Validation score   (accuracy)\n",
      "\t0.95s\t = Training   runtime\n",
      "\t1.48s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1659.58s of the 6256.34s of remaining time.\n",
      "Will use sequential fold fitting strategy because import of ray failed. Reason: ray==2.31.0 detected. 2.10.0 <= ray < 2.11.0 is required. You can use pip to install certain version of ray `pip install ray==2.10.0` \n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 4: early stopping\n",
      "No improvement since epoch 2: early stopping\n",
      "No improvement since epoch 3: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 2: early stopping\n",
      "No improvement since epoch 2: early stopping\n",
      "\t0.2377\t = Validation score   (accuracy)\n",
      "\t131.18s\t = Training   runtime\n",
      "\t0.66s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1525.15s of the 6121.92s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ag\\lib\\site-packages\\dask\\dataframe\\__init__.py:42: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "\t0.3794\t = Validation score   (accuracy)\n",
      "\t116.52s\t = Training   runtime\n",
      "\t0.72s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1404.66s of the 6001.38s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.3783\t = Validation score   (accuracy)\n",
      "\t129.17s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 1271.92s of the 5868.64s of remaining time.\n",
      "\t0.3124\t = Validation score   (accuracy)\n",
      "\t16.33s\t = Training   runtime\n",
      "\t15.89s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 1238.17s of the 5834.94s of remaining time.\n",
      "\t0.3004\t = Validation score   (accuracy)\n",
      "\t14.14s\t = Training   runtime\n",
      "\t15.87s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1206.61s of the 5803.37s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tMany features detected (4059), dynamically setting 'colsample_bylevel' to 0.2463661000246366 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 401.\n",
      "\tMany features detected (4059), dynamically setting 'colsample_bylevel' to 0.2463661000246366 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 409.\n",
      "\tMany features detected (4059), dynamically setting 'colsample_bylevel' to 0.2463661000246366 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 420.\n",
      "\tMany features detected (4059), dynamically setting 'colsample_bylevel' to 0.2463661000246366 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 442.\n",
      "\tMany features detected (4058), dynamically setting 'colsample_bylevel' to 0.2464268112370626 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 459.\n",
      "\tMany features detected (4056), dynamically setting 'colsample_bylevel' to 0.2465483234714004 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 484.\n",
      "\tMany features detected (4056), dynamically setting 'colsample_bylevel' to 0.2465483234714004 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 537.\n",
      "\tMany features detected (4058), dynamically setting 'colsample_bylevel' to 0.2464268112370626 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 666.\n",
      "\t0.3725\t = Validation score   (accuracy)\n",
      "\t1155.85s\t = Training   runtime\n",
      "\t2.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 46.36s of the 4643.13s of remaining time.\n",
      "\t0.3113\t = Validation score   (accuracy)\n",
      "\t18.62s\t = Training   runtime\n",
      "\t16.31s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 9.95s of the 4606.71s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 110 due to low time. Expected time usage reduced from 25.8s -> 9.9s...\n",
      "\t0.291\t = Validation score   (accuracy)\n",
      "\t6.65s\t = Training   runtime\n",
      "\t5.77s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 4584.8s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.333, 'LightGBM_BAG_L1': 0.333, 'CatBoost_BAG_L1': 0.333}\n",
      "\t0.3873\t = Validation score   (accuracy)\n",
      "\t0.48s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 1527.71s of the 4583.81s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 2: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 2: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "\t0.4274\t = Validation score   (accuracy)\n",
      "\t122.21s\t = Training   runtime\n",
      "\t0.72s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 1401.7s of the 4457.82s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.5229\t = Validation score   (accuracy)\n",
      "\t534.88s\t = Training   runtime\n",
      "\t0.89s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 860.95s of the 3917.0s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 533. Best iteration is:\n",
      "\t[280]\tvalid_set's multi_error: 0.476052\n",
      "\t0.5205\t = Validation score   (accuracy)\n",
      "\t700.42s\t = Training   runtime\n",
      "\t0.99s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 154.53s of the 3210.39s of remaining time.\n",
      "\t0.4967\t = Validation score   (accuracy)\n",
      "\t4.59s\t = Training   runtime\n",
      "\t16.62s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 130.66s of the 3186.77s of remaining time.\n",
      "\t0.4766\t = Validation score   (accuracy)\n",
      "\t4.59s\t = Training   runtime\n",
      "\t16.57s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 107.68s of the 3163.75s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tMany features detected (4317), dynamically setting 'colsample_bylevel' to 0.23164234422052352 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 28.\n",
      "\tMany features detected (4318), dynamically setting 'colsample_bylevel' to 0.2315886984715146 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 24.\n",
      "\tMany features detected (4318), dynamically setting 'colsample_bylevel' to 0.2315886984715146 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 24.\n",
      "\tMany features detected (4318), dynamically setting 'colsample_bylevel' to 0.2315886984715146 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 25.\n",
      "\tMany features detected (4318), dynamically setting 'colsample_bylevel' to 0.2315886984715146 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 26.\n",
      "\tMany features detected (4319), dynamically setting 'colsample_bylevel' to 0.23153507756425099 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 27.\n",
      "\tMany features detected (4315), dynamically setting 'colsample_bylevel' to 0.23174971031286212 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 31.\n",
      "\tMany features detected (4318), dynamically setting 'colsample_bylevel' to 0.2315886984715146 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 34.\n",
      "\t0.416\t = Validation score   (accuracy)\n",
      "\t102.31s\t = Training   runtime\n",
      "\t1.18s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 1.49s of the 3057.61s of remaining time.\n",
      "\tWarning: Model is expected to require 7.3s to train, which exceeds the maximum time limit of 1.5s, skipping model...\n",
      "\tTime limit exceeded... Skipping ExtraTreesGini_BAG_L2.\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 3015.6s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 0.417, 'RandomForestGini_BAG_L2': 0.167, 'RandomForestEntr_BAG_L2': 0.167, 'CatBoost_BAG_L2': 0.167, 'NeuralNetFastAI_BAG_L2': 0.042, 'LightGBM_BAG_L2': 0.042}\n",
      "\t0.5258\t = Validation score   (accuracy)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L3 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L3 ... Training model for up to 1339.78s of the 3014.83s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "\t0.453\t = Validation score   (accuracy)\n",
      "\t119.67s\t = Training   runtime\n",
      "\t0.75s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L3 ... Training model for up to 1216.39s of the 2891.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.5163\t = Validation score   (accuracy)\n",
      "\t389.16s\t = Training   runtime\n",
      "\t0.83s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L3 ... Training model for up to 822.16s of the 2497.17s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.5083\t = Validation score   (accuracy)\n",
      "\t638.92s\t = Training   runtime\n",
      "\t0.91s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L3 ... Training model for up to 177.62s of the 1852.63s of remaining time.\n",
      "\t0.4964\t = Validation score   (accuracy)\n",
      "\t4.15s\t = Training   runtime\n",
      "\t16.33s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L3 ... Training model for up to 155.36s of the 1830.4s of remaining time.\n",
      "\t0.481\t = Validation score   (accuracy)\n",
      "\t4.36s\t = Training   runtime\n",
      "\t16.44s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L3 ... Training model for up to 132.78s of the 1807.84s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tMany features detected (4214), dynamically setting 'colsample_bylevel' to 0.23730422401518747 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 38.\n",
      "\tMany features detected (4214), dynamically setting 'colsample_bylevel' to 0.23730422401518747 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 34.\n",
      "\tMany features detected (4212), dynamically setting 'colsample_bylevel' to 0.23741690408357075 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 34.\n",
      "\tMany features detected (4215), dynamically setting 'colsample_bylevel' to 0.2372479240806643 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 37.\n",
      "\tMany features detected (4214), dynamically setting 'colsample_bylevel' to 0.23730422401518747 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 37.\n",
      "\tMany features detected (4215), dynamically setting 'colsample_bylevel' to 0.2372479240806643 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 40.\n",
      "\tMany features detected (4214), dynamically setting 'colsample_bylevel' to 0.23730422401518747 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 43.\n",
      "\tMany features detected (4213), dynamically setting 'colsample_bylevel' to 0.23736055067647757 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 50.\n",
      "\t0.4526\t = Validation score   (accuracy)\n",
      "\t126.33s\t = Training   runtime\n",
      "\t1.15s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L3 ... Training model for up to 2.73s of the 1677.79s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 83 due to low time. Expected time usage reduced from 8.0s -> 2.7s...\n",
      "\t0.4924\t = Validation score   (accuracy)\n",
      "\t2.49s\t = Training   runtime\n",
      "\t4.55s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L4 ... Training model for up to 360.0s of the 1632.81s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L3': 1.0}\n",
      "\t0.5163\t = Validation score   (accuracy)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L4 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L4 ... Training model for up to 1088.01s of the 1632.0s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 2: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "\t0.4441\t = Validation score   (accuracy)\n",
      "\t121.06s\t = Training   runtime\n",
      "\t0.69s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L4 ... Training model for up to 963.32s of the 1507.31s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.5098\t = Validation score   (accuracy)\n",
      "\t397.05s\t = Training   runtime\n",
      "\t0.85s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L4 ... Training model for up to 561.25s of the 1105.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 229. Best iteration is:\n",
      "\t[30]\tvalid_set's multi_error: 0.465893\n",
      "\tRan out of time, early stopping on iteration 176. Best iteration is:\n",
      "\t[25]\tvalid_set's multi_error: 0.515239\n",
      "\tRan out of time, early stopping on iteration 246. Best iteration is:\n",
      "\t[29]\tvalid_set's multi_error: 0.480406\n",
      "\tRan out of time, early stopping on iteration 197. Best iteration is:\n",
      "\t[84]\tvalid_set's multi_error: 0.53701\n",
      "\tRan out of time, early stopping on iteration 326. Best iteration is:\n",
      "\t[56]\tvalid_set's multi_error: 0.500726\n",
      "\tRan out of time, early stopping on iteration 222. Best iteration is:\n",
      "\t[71]\tvalid_set's multi_error: 0.461538\n",
      "\tRan out of time, early stopping on iteration 277. Best iteration is:\n",
      "\t[210]\tvalid_set's multi_error: 0.460087\n",
      "\t0.5087\t = Validation score   (accuracy)\n",
      "\t526.0s\t = Training   runtime\n",
      "\t0.84s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L4 ... Training model for up to 30.26s of the 574.22s of remaining time.\n",
      "\t0.4949\t = Validation score   (accuracy)\n",
      "\t4.28s\t = Training   runtime\n",
      "\t16.67s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L4 ... Training model for up to 7.55s of the 551.53s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 222 due to low time. Expected time usage reduced from 10.0s -> 7.6s...\n",
      "\t0.4828\t = Validation score   (accuracy)\n",
      "\t3.78s\t = Training   runtime\n",
      "\t11.99s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L5 ... Training model for up to 360.0s of the 496.03s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L4': 1.0}\n",
      "\t0.5098\t = Validation score   (accuracy)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L5 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L5 ... Training model for up to 495.73s of the 495.29s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "\t0.4354\t = Validation score   (accuracy)\n",
      "\t122.12s\t = Training   runtime\n",
      "\t0.71s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L5 ... Training model for up to 369.93s of the 369.51s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 268. Best iteration is:\n",
      "\t[13]\tvalid_set's multi_error: 0.478955\n",
      "\tRan out of time, early stopping on iteration 259. Best iteration is:\n",
      "\t[145]\tvalid_set's multi_error: 0.490566\n",
      "\tRan out of time, early stopping on iteration 283. Best iteration is:\n",
      "\t[224]\tvalid_set's multi_error: 0.486212\n",
      "\tRan out of time, early stopping on iteration 296. Best iteration is:\n",
      "\t[37]\tvalid_set's multi_error: 0.484761\n",
      "\tRan out of time, early stopping on iteration 295. Best iteration is:\n",
      "\t[32]\tvalid_set's multi_error: 0.496372\n",
      "\tRan out of time, early stopping on iteration 395. Best iteration is:\n",
      "\t[202]\tvalid_set's multi_error: 0.500726\n",
      "\t0.5083\t = Validation score   (accuracy)\n",
      "\t336.76s\t = Training   runtime\n",
      "\t0.83s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L5 ... Training model for up to 28.55s of the 28.06s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 10. Best iteration is:\n",
      "\t[10]\tvalid_set's multi_error: 0.519594\n",
      "\tTime limit exceeded... Skipping LightGBM_BAG_L5.\n",
      "Fitting model: RandomForestGini_BAG_L5 ... Training model for up to 22.42s of the 21.97s of remaining time.\n",
      "\t0.4849\t = Validation score   (accuracy)\n",
      "\t4.26s\t = Training   runtime\n",
      "\t16.05s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L6 ... Training model for up to 360.0s of the -37.12s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 0.222, 'LightGBM_BAG_L2': 0.167, 'NeuralNetFastAI_BAG_L3': 0.111, 'LightGBMXT_BAG_L3': 0.111, 'RandomForestGini_BAG_L3': 0.111, 'NeuralNetFastAI_BAG_L5': 0.111, 'ExtraTreesGini_BAG_L1': 0.056, 'CatBoost_BAG_L2': 0.056, 'LightGBMXT_BAG_L4': 0.056}\n",
      "\t0.5305\t = Validation score   (accuracy)\n",
      "\t1.1s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 6337.38s ... Best model: WeightedEnsemble_L6 | Estimated inference throughput: 20.2 rows/s (689 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20241009_172807\\ds_sub_fit\\sub_fit_ho\")\n",
      "Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                      model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0       WeightedEnsemble_L3       0.541364   0.525762    accuracy       12.811353      97.965562  3059.676674                 0.009017                0.001013           0.324748            3       True         18\n",
      "1       WeightedEnsemble_L6       0.541364   0.530479    accuracy       23.984285     170.667429  5519.826740                 0.010000                0.001999           1.095841            6       True         36\n",
      "2         LightGBMXT_BAG_L2       0.532656   0.522859    accuracy        8.095444      61.886525  2125.238472                 1.487891                0.892184         534.877879            2       True         13\n",
      "3           LightGBM_BAG_L3       0.531205   0.508345    accuracy       14.295289      98.873666  3698.275200                 1.492953                0.909117         638.923274            3       True         21\n",
      "4         LightGBMXT_BAG_L4       0.529753   0.509797    accuracy       19.953148     139.773979  4741.488801                 1.341136                0.849968         397.045083            4       True         28\n",
      "5       WeightedEnsemble_L5       0.529753   0.509797    accuracy       19.970147     139.775973  4741.768985                 0.017000                0.001994           0.280184            5       True         32\n",
      "6         LightGBMXT_BAG_L3       0.528302   0.516328    accuracy       14.068944      98.790106  3448.516216                 1.266608                0.825557         389.164290            3       True         20\n",
      "7       WeightedEnsemble_L4       0.528302   0.516328    accuracy       14.081121      98.791102  3448.877658                 0.012177                0.000996           0.361442            4       True         26\n",
      "8           LightGBM_BAG_L2       0.525399   0.520501    accuracy        8.037510      61.981777  2290.776608                 1.429957                0.987436         700.416016            2       True         14\n",
      "9   RandomForestGini_BAG_L3       0.521045   0.496372    accuracy       13.180759     114.294843  3063.502076                 0.378423               16.330294           4.150150            3       True         22\n",
      "10        LightGBMXT_BAG_L5       0.521045   0.508345    accuracy       24.251096     170.792328  5733.368519                 1.221497                0.832850         336.762330            5       True         34\n",
      "11    ExtraTreesGini_BAG_L3       0.519594   0.492380    accuracy       12.915850     102.513469  3061.846477                 0.113514                4.548921           2.494551            3       True         25\n",
      "12          LightGBM_BAG_L4       0.518142   0.508708    accuracy       20.027817     139.759331  4870.442603                 1.415805                0.835320         525.998885            4       True         29\n",
      "13  RandomForestGini_BAG_L4       0.512337   0.494920    accuracy       18.990452     155.589940  4348.719180                 0.378440               16.665930           4.275462            4       True         30\n",
      "14  RandomForestGini_BAG_L5       0.512337   0.484942    accuracy       23.437443     186.007239  5400.870829                 0.407843               16.047762           4.264640            5       True         35\n",
      "15  RandomForestGini_BAG_L2       0.507983   0.496734    accuracy        6.972898      77.615511  1594.954569                 0.365345               16.621169           4.593976            2       True         15\n",
      "16  RandomForestEntr_BAG_L4       0.500726   0.482765    accuracy       18.893506     150.914581  4348.222226                 0.281494               11.990570           3.778508            4       True         31\n",
      "17  RandomForestEntr_BAG_L3       0.490566   0.480951    accuracy       13.166872     114.407727  3063.714350                 0.364536               16.443178           4.362424            3       True         23\n",
      "18   NeuralNetFastAI_BAG_L4       0.487663   0.444122    accuracy       19.612724     139.617689  4465.508251                 1.000712                0.693678         121.064533            4       True         27\n",
      "19   NeuralNetFastAI_BAG_L3       0.486212   0.453012    accuracy       13.792986      98.717050  3179.018568                 0.990650                0.752501         119.666642            3       True         19\n",
      "20   NeuralNetFastAI_BAG_L2       0.480406   0.427431    accuracy        7.712100      61.715940  1712.566085                 1.104547                0.721598         122.205492            2       True         12\n",
      "21  RandomForestEntr_BAG_L2       0.478955   0.476597    accuracy        6.984207      77.562791  1594.952293                 0.376654               16.568450           4.591701            2       True         16\n",
      "22   NeuralNetFastAI_BAG_L5       0.471698   0.435414    accuracy       23.974285     170.665430  5518.730899                 0.944686                0.705952         122.124710            5       True         33\n",
      "23          CatBoost_BAG_L3       0.468795   0.452649    accuracy       14.005327      99.114443  3185.682387                 1.202991                1.149894         126.330461            3       True         24\n",
      "24          CatBoost_BAG_L2       0.447025   0.416001    accuracy        8.037942      62.173712  1692.666862                 1.430389                1.179370         102.306269            2       True         17\n",
      "25      WeightedEnsemble_L2       0.377358   0.387337    accuracy        3.422005       3.375558  1402.022978                 0.007006                0.001001           0.480034            2       True         11\n",
      "26        LightGBMXT_BAG_L1       0.368650   0.379354    accuracy        1.080617       0.716229   116.523169                 1.080617                0.716229         116.523169            1       True          4\n",
      "27          LightGBM_BAG_L1       0.362845   0.378266    accuracy        0.849101       0.604813   129.169784                 0.849101                0.604813         129.169784            1       True          5\n",
      "28          CatBoost_BAG_L1       0.345428   0.372460    accuracy        1.485280       2.053515  1155.849991                 1.485280                2.053515        1155.849991            1       True          8\n",
      "29    ExtraTreesGini_BAG_L1       0.304790   0.311321    accuracy        0.443965      16.311415    18.618646                 0.443965               16.311415          18.618646            1       True          9\n",
      "30  RandomForestGini_BAG_L1       0.300435   0.312409    accuracy        0.466646      15.888576    16.329726                 0.466646               15.888576          16.329726            1       True          6\n",
      "31  RandomForestEntr_BAG_L1       0.298984   0.300435    accuracy        0.461738      15.865025    14.136937                 0.461738               15.865025          14.136937            1       True          7\n",
      "32    ExtraTreesEntr_BAG_L1       0.290276   0.291001    accuracy        0.192620       5.774865     6.651922                 0.192620                5.774865           6.651922            1       True         10\n",
      "33   NeuralNetFastAI_BAG_L1       0.252540   0.237663    accuracy        0.947475       0.664580   131.180839                 0.947475                0.664580         131.180839            1       True          3\n",
      "34    KNeighborsUnif_BAG_L1       0.238026   0.230769    accuracy        0.344542       1.633001     0.945324                 0.344542                1.633001           0.945324            1       True          1\n",
      "35    KNeighborsDist_BAG_L1       0.219158   0.220065    accuracy        0.335568       1.482322     0.954254                 0.335568                1.482322           0.954254            1       True          2\n",
      "\t4\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t6365s\t = DyStack   runtime |\t18835s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=4.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=4)`\n",
      "Beginning AutoGluon training ... Time limit = 18835s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20241009_172807\"\n",
      "Train Data Rows:    6201\n",
      "Train Data Columns: 4225\n",
      "Label Column:       SUBCLASS\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 26\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    21888.94 MB\n",
      "\tTrain Data (Original)  Memory Usage: 199.88 MB (0.9% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 87 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 8): ['AP2S1', 'CEBPD', 'CTF1', 'FKBP1B', 'GADD45A', 'MT1E', 'PCSK1N', 'TMEM158']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 160): ['APOC3', 'ATOX1', 'ATP6V0E1', 'BET1', 'BLCAP', 'BRF2', 'BRMS1L', 'BST2', 'C8G', 'CAV2', 'CBX5', 'CCL11', 'CD302', 'CD69', 'CDK6', 'CHCHD10', 'CHMP1A', 'CKS1B', 'COX5A', 'COX5B', 'COX6C', 'COX7B', 'COX7C', 'CRABP1', 'CRB3', 'CSRP1', 'CXCL13', 'CYB5R1', 'DAP', 'DCTN4', 'DCXR', 'DDT', 'DUSP2', 'EBI3', 'EBP', 'EIF1', 'EIF1B', 'EIF4EBP1', 'ENDOD1', 'EXOSC1', 'FABP1', 'FKBP1A', 'FKBP2', 'FLOT2', 'FXN', 'GHRL', 'GNG2', 'GNGT1', 'GPX3', 'GPX8', 'GTF2A2', 'HADH', 'HEY1', 'HOXD11', 'HSD17B10', 'ID1', 'IFI27', 'IGFBP6', 'IKBKG', 'IMPDH2', 'ISG15', 'KLF2', 'LEAP2', 'LGALS7', 'LSM1', 'LSM2', 'LSM7', 'LXN', 'MAFF', 'MAGIX', 'MAL2', 'MIF', 'MRPS12', 'MSRB2', 'MT3', 'MTX2', 'MXD3', 'MYL6B', 'NDUFA2', 'NDUFA3', 'NDUFA4', 'NDUFB4', 'NDUFC2', 'NINJ1', 'NIP7', 'NME1', 'NRTN', 'NUPR1', 'PBK', 'PCBD1', 'PDE6G', 'PEMT', 'PFN1', 'PFN2', 'PHLDA3', 'PIM3', 'PLSCR1', 'PMAIP1', 'POLD4', 'POLE4', 'POP7', 'PPP3R1', 'PROK2', 'PSMB3', 'PSMD14', 'PTGES', 'PTS', 'PTTG1', 'PURA', 'PVALB', 'PYCR1', 'RBM38', 'RBPMS', 'REEP6', 'RNF4', 'RNH1', 'RPS10', 'RPS12', 'RPS3', 'RPS6', 'S100A4', 'S100A9', 'SCG5', 'SDF2L1', 'SIGMAR1', 'SLC37A4', 'SMPX', 'SNAPC5', 'SNN', 'SNRPD1', 'SNRPD3', 'SNRPG', 'SOCS3', 'SPCS1', 'SPR', 'SRI', 'SRP14', 'SRP9', 'SRSF10', 'TAF12', 'TAX1BP3', 'TBC1D30', 'TCAP', 'TFF3', 'TIMM10', 'TIMM13', 'TIMM9', 'TIMP1', 'TMEM9B', 'TPRKB', 'TSPO', 'TXN', 'TYMS', 'UBE2L3', 'UBE2S', 'UQCR11', 'UQCRH', 'UXT', 'VAMP8', 'YPEL5']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('int', []) : 160 | ['APOC3', 'ATOX1', 'ATP6V0E1', 'BET1', 'BLCAP', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', []) : 4057 | ['A2M', 'AAAS', 'AADAT', 'ABAT', 'ABCA1', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('int', [])       : 4013 | ['A2M', 'AAAS', 'AADAT', 'ABAT', 'ABCA1', ...]\n",
      "\t\t('int', ['bool']) :   44 | ['ARHGDIA', 'ARPC3', 'CCL2', 'CCL22', 'CFD', ...]\n",
      "\t29.8s = Fit runtime\n",
      "\t4057 features in original data used to generate 4057 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 190.11 MB (0.9% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 30.46s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 5 stack levels (L1 to L5) ...\n",
      "Fitting 110 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 5013.3s of the 18804.49s of remaining time.\n",
      "\t0.2256\t = Validation score   (accuracy)\n",
      "\t0.99s\t = Training   runtime\n",
      "\t1.93s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 5009.05s of the 18800.24s of remaining time.\n",
      "\t0.2174\t = Validation score   (accuracy)\n",
      "\t0.99s\t = Training   runtime\n",
      "\t2.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 5004.71s of the 18795.9s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 2: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 2: early stopping\n",
      "No improvement since epoch 2: early stopping\n",
      "No improvement since epoch 5: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 3: early stopping\n",
      "\t0.2429\t = Validation score   (accuracy)\n",
      "\t138.54s\t = Training   runtime\n",
      "\t0.72s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 4862.69s of the 18653.88s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.3848\t = Validation score   (accuracy)\n",
      "\t121.83s\t = Training   runtime\n",
      "\t0.72s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 4737.06s of the 18528.2s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.3833\t = Validation score   (accuracy)\n",
      "\t148.46s\t = Training   runtime\n",
      "\t0.75s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 4584.85s of the 18375.99s of remaining time.\n",
      "\t0.3038\t = Validation score   (accuracy)\n",
      "\t20.03s\t = Training   runtime\n",
      "\t18.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 4545.12s of the 18336.3s of remaining time.\n",
      "\t0.2908\t = Validation score   (accuracy)\n",
      "\t17.63s\t = Training   runtime\n",
      "\t18.25s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 4507.63s of the 18298.81s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tMany features detected (4056), dynamically setting 'colsample_bylevel' to 0.2465483234714004 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tMany features detected (4055), dynamically setting 'colsample_bylevel' to 0.2466091245376079 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tMany features detected (4056), dynamically setting 'colsample_bylevel' to 0.2465483234714004 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tMany features detected (4057), dynamically setting 'colsample_bylevel' to 0.24648755237860487 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tMany features detected (4057), dynamically setting 'colsample_bylevel' to 0.24648755237860487 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tMany features detected (4052), dynamically setting 'colsample_bylevel' to 0.24679170779861798 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tMany features detected (4057), dynamically setting 'colsample_bylevel' to 0.24648755237860487 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tMany features detected (4054), dynamically setting 'colsample_bylevel' to 0.246669955599408 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\t0.3825\t = Validation score   (accuracy)\n",
      "\t3059.46s\t = Training   runtime\n",
      "\t1.64s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 1444.07s of the 15235.26s of remaining time.\n",
      "\t0.3095\t = Validation score   (accuracy)\n",
      "\t23.64s\t = Training   runtime\n",
      "\t18.14s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 1400.7s of the 15191.88s of remaining time.\n",
      "\t0.2922\t = Validation score   (accuracy)\n",
      "\t20.75s\t = Training   runtime\n",
      "\t18.35s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1360.04s of the 15151.23s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.3743\t = Validation score   (accuracy)\n",
      "\t231.46s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1124.02s of the 14915.2s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ag\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:1623: FutureWarning: \n",
      "The format of the columns of the 'remainder' transformer in ColumnTransformer.transformers_ will change in version 1.7 to match the format of the other transformers.\n",
      "At the moment the remainder columns are stored as indices (of type int). With the same ColumnTransformer configuration, in the future they will be stored as column names (of type str).\n",
      "To use the new behavior now and suppress this warning, use ColumnTransformer(force_int_remainder_cols=False).\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ag\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:1623: FutureWarning: \n",
      "The format of the columns of the 'remainder' transformer in ColumnTransformer.transformers_ will change in version 1.7 to match the format of the other transformers.\n",
      "At the moment the remainder columns are stored as indices (of type int). With the same ColumnTransformer configuration, in the future they will be stored as column names (of type str).\n",
      "To use the new behavior now and suppress this warning, use ColumnTransformer(force_int_remainder_cols=False).\n",
      "\n",
      "  warnings.warn(\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 124)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ag\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:1623: FutureWarning: \n",
      "The format of the columns of the 'remainder' transformer in ColumnTransformer.transformers_ will change in version 1.7 to match the format of the other transformers.\n",
      "At the moment the remainder columns are stored as indices (of type int). With the same ColumnTransformer configuration, in the future they will be stored as column names (of type str).\n",
      "To use the new behavior now and suppress this warning, use ColumnTransformer(force_int_remainder_cols=False).\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ag\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:1623: FutureWarning: \n",
      "The format of the columns of the 'remainder' transformer in ColumnTransformer.transformers_ will change in version 1.7 to match the format of the other transformers.\n",
      "At the moment the remainder columns are stored as indices (of type int). With the same ColumnTransformer configuration, in the future they will be stored as column names (of type str).\n",
      "To use the new behavior now and suppress this warning, use ColumnTransformer(force_int_remainder_cols=False).\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ag\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:1623: FutureWarning: \n",
      "The format of the columns of the 'remainder' transformer in ColumnTransformer.transformers_ will change in version 1.7 to match the format of the other transformers.\n",
      "At the moment the remainder columns are stored as indices (of type int). With the same ColumnTransformer configuration, in the future they will be stored as column names (of type str).\n",
      "To use the new behavior now and suppress this warning, use ColumnTransformer(force_int_remainder_cols=False).\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ag\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:1623: FutureWarning: \n",
      "The format of the columns of the 'remainder' transformer in ColumnTransformer.transformers_ will change in version 1.7 to match the format of the other transformers.\n",
      "At the moment the remainder columns are stored as indices (of type int). With the same ColumnTransformer configuration, in the future they will be stored as column names (of type str).\n",
      "To use the new behavior now and suppress this warning, use ColumnTransformer(force_int_remainder_cols=False).\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ag\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:1623: FutureWarning: \n",
      "The format of the columns of the 'remainder' transformer in ColumnTransformer.transformers_ will change in version 1.7 to match the format of the other transformers.\n",
      "At the moment the remainder columns are stored as indices (of type int). With the same ColumnTransformer configuration, in the future they will be stored as column names (of type str).\n",
      "To use the new behavior now and suppress this warning, use ColumnTransformer(force_int_remainder_cols=False).\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ag\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:1623: FutureWarning: \n",
      "The format of the columns of the 'remainder' transformer in ColumnTransformer.transformers_ will change in version 1.7 to match the format of the other transformers.\n",
      "At the moment the remainder columns are stored as indices (of type int). With the same ColumnTransformer configuration, in the future they will be stored as column names (of type str).\n",
      "To use the new behavior now and suppress this warning, use ColumnTransformer(force_int_remainder_cols=False).\n",
      "\n",
      "  warnings.warn(\n",
      "\t0.158\t = Validation score   (accuracy)\n",
      "\t388.57s\t = Training   runtime\n",
      "\t8.08s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 724.85s of the 14516.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 299. Best iteration is:\n",
      "\t[39]\tvalid_set's multi_error: 0.680412\n",
      "\tRan out of time, early stopping on iteration 312. Best iteration is:\n",
      "\t[38]\tvalid_set's multi_error: 0.669677\n",
      "\tRan out of time, early stopping on iteration 417. Best iteration is:\n",
      "\t[397]\tvalid_set's multi_error: 0.674839\n",
      "\t0.3195\t = Validation score   (accuracy)\n",
      "\t636.27s\t = Training   runtime\n",
      "\t1.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 82.35s of the 13873.54s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tMany features detected (4056), dynamically setting 'colsample_bylevel' to 0.2465483234714004 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 21.\n",
      "\tMany features detected (4055), dynamically setting 'colsample_bylevel' to 0.2466091245376079 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 19.\n",
      "\tMany features detected (4056), dynamically setting 'colsample_bylevel' to 0.2465483234714004 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 20.\n",
      "\tMany features detected (4057), dynamically setting 'colsample_bylevel' to 0.24648755237860487 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 22.\n",
      "\tMany features detected (4057), dynamically setting 'colsample_bylevel' to 0.24648755237860487 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 22.\n",
      "\tMany features detected (4052), dynamically setting 'colsample_bylevel' to 0.24679170779861798 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 23.\n",
      "\tMany features detected (4057), dynamically setting 'colsample_bylevel' to 0.24648755237860487 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 24.\n",
      "\tMany features detected (4054), dynamically setting 'colsample_bylevel' to 0.246669955599408 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 28.\n",
      "\t0.2577\t = Validation score   (accuracy)\n",
      "\t77.33s\t = Training   runtime\n",
      "\t1.99s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 0.62s of the 13791.81s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_r79_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 501.33s of the 13781.73s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.304, 'LightGBM_BAG_L1': 0.304, 'CatBoost_BAG_L1': 0.217, 'CatBoost_r177_BAG_L1': 0.13, 'NeuralNetTorch_BAG_L1': 0.043}\n",
      "\t0.3927\t = Validation score   (accuracy)\n",
      "\t0.78s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 4592.48s of the 13780.39s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "\t0.4583\t = Validation score   (accuracy)\n",
      "\t147.39s\t = Training   runtime\n",
      "\t0.84s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 4441.02s of the 13628.94s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.5427\t = Validation score   (accuracy)\n",
      "\t754.61s\t = Training   runtime\n",
      "\t1.12s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 3680.6s of the 12868.46s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.5339\t = Validation score   (accuracy)\n",
      "\t1135.65s\t = Training   runtime\n",
      "\t1.09s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 2538.36s of the 11726.22s of remaining time.\n",
      "\t0.5156\t = Validation score   (accuracy)\n",
      "\t5.13s\t = Training   runtime\n",
      "\t19.52s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 2511.73s of the 11699.64s of remaining time.\n",
      "\t0.4912\t = Validation score   (accuracy)\n",
      "\t5.84s\t = Training   runtime\n",
      "\t19.34s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 2484.6s of the 11672.52s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tMany features detected (4420), dynamically setting 'colsample_bylevel' to 0.22624434389140272 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 499.\n",
      "\tMany features detected (4417), dynamically setting 'colsample_bylevel' to 0.22639800769753227 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 498.\n",
      "\tMany features detected (4420), dynamically setting 'colsample_bylevel' to 0.22624434389140272 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 517.\n",
      "\tMany features detected (4420), dynamically setting 'colsample_bylevel' to 0.22624434389140272 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 538.\n",
      "\tMany features detected (4419), dynamically setting 'colsample_bylevel' to 0.22629554197782303 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 564.\n",
      "\tMany features detected (4420), dynamically setting 'colsample_bylevel' to 0.22624434389140272 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 596.\n",
      "\tMany features detected (4418), dynamically setting 'colsample_bylevel' to 0.22634676324128564 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 661.\n",
      "\tMany features detected (4419), dynamically setting 'colsample_bylevel' to 0.22629554197782303 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 786.\n",
      "\t0.5378\t = Validation score   (accuracy)\n",
      "\t2382.23s\t = Training   runtime\n",
      "\t1.44s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 98.02s of the 9285.94s of remaining time.\n",
      "\t0.5041\t = Validation score   (accuracy)\n",
      "\t5.63s\t = Training   runtime\n",
      "\t19.43s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 70.92s of the 9258.82s of remaining time.\n",
      "\t0.4883\t = Validation score   (accuracy)\n",
      "\t4.85s\t = Training   runtime\n",
      "\t19.62s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 44.47s of the 9232.39s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping XGBoost_BAG_L2.\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 35.7s of the 9223.62s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ag\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:1623: FutureWarning: \n",
      "The format of the columns of the 'remainder' transformer in ColumnTransformer.transformers_ will change in version 1.7 to match the format of the other transformers.\n",
      "At the moment the remainder columns are stored as indices (of type int). With the same ColumnTransformer configuration, in the future they will be stored as column names (of type str).\n",
      "To use the new behavior now and suppress this warning, use ColumnTransformer(force_int_remainder_cols=False).\n",
      "\n",
      "  warnings.warn(\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_BAG_L2.\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 24.71s of the 9212.64s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 2. Best iteration is:\n",
      "\t[2]\tvalid_set's multi_error: 0.673969\n",
      "\tTime limit exceeded... Skipping LightGBMLarge_BAG_L2.\n",
      "Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 16.88s of the 9204.81s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tMany features detected (4420), dynamically setting 'colsample_bylevel' to 0.22624434389140272 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 1.\n",
      "\tTime limit exceeded... Skipping CatBoost_r177_BAG_L2.\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 11.9s of the 9199.83s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ag\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:1623: FutureWarning: \n",
      "The format of the columns of the 'remainder' transformer in ColumnTransformer.transformers_ will change in version 1.7 to match the format of the other transformers.\n",
      "At the moment the remainder columns are stored as indices (of type int). With the same ColumnTransformer configuration, in the future they will be stored as column names (of type str).\n",
      "To use the new behavior now and suppress this warning, use ColumnTransformer(force_int_remainder_cols=False).\n",
      "\n",
      "  warnings.warn(\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_r79_BAG_L2.\n",
      "Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 1.0s of the 9188.91s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 1. Best iteration is:\n",
      "\t[1]\tvalid_set's multi_error: 0.873711\n",
      "\tTime limit exceeded... Skipping LightGBM_r131_BAG_L2.\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 459.25s of the 9145.56s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 0.682, 'RandomForestGini_BAG_L2': 0.182, 'NeuralNetFastAI_BAG_L2': 0.091, 'RandomForestEntr_BAG_L2': 0.045}\n",
      "\t0.5448\t = Validation score   (accuracy)\n",
      "\t0.45s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L3 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L3 ... Training model for up to 4063.46s of the 9144.63s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "\t0.4773\t = Validation score   (accuracy)\n",
      "\t145.12s\t = Training   runtime\n",
      "\t0.81s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L3 ... Training model for up to 3914.49s of the 8995.65s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.5367\t = Validation score   (accuracy)\n",
      "\t536.54s\t = Training   runtime\n",
      "\t1.21s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L3 ... Training model for up to 3371.29s of the 8452.44s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.5362\t = Validation score   (accuracy)\n",
      "\t818.75s\t = Training   runtime\n",
      "\t1.15s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L3 ... Training model for up to 2546.62s of the 7627.77s of remaining time.\n",
      "\t0.5207\t = Validation score   (accuracy)\n",
      "\t4.8s\t = Training   runtime\n",
      "\t18.8s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L3 ... Training model for up to 2521.15s of the 7602.32s of remaining time.\n",
      "\t0.5065\t = Validation score   (accuracy)\n",
      "\t4.87s\t = Training   runtime\n",
      "\t18.86s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L3 ... Training model for up to 2495.6s of the 7576.77s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tMany features detected (4260), dynamically setting 'colsample_bylevel' to 0.2347417840375587 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 556.\n",
      "\tMany features detected (4262), dynamically setting 'colsample_bylevel' to 0.2346316283435007 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tMany features detected (4265), dynamically setting 'colsample_bylevel' to 0.23446658851113716 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 584.\n",
      "\tMany features detected (4263), dynamically setting 'colsample_bylevel' to 0.23457658925639222 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 608.\n",
      "\tMany features detected (4264), dynamically setting 'colsample_bylevel' to 0.23452157598499063 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tMany features detected (4265), dynamically setting 'colsample_bylevel' to 0.23446658851113716 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tMany features detected (4264), dynamically setting 'colsample_bylevel' to 0.23452157598499063 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tMany features detected (4264), dynamically setting 'colsample_bylevel' to 0.23452157598499063 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\t0.5462\t = Validation score   (accuracy)\n",
      "\t2228.86s\t = Training   runtime\n",
      "\t1.34s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L3 ... Training model for up to 262.61s of the 5343.79s of remaining time.\n",
      "\t0.5283\t = Validation score   (accuracy)\n",
      "\t5.63s\t = Training   runtime\n",
      "\t18.91s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L3 ... Training model for up to 236.22s of the 5317.4s of remaining time.\n",
      "\t0.5152\t = Validation score   (accuracy)\n",
      "\t5.09s\t = Training   runtime\n",
      "\t19.01s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L3 ... Training model for up to 210.24s of the 5291.42s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.5335\t = Validation score   (accuracy)\n",
      "\t202.15s\t = Training   runtime\n",
      "\t0.7s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L3 ... Training model for up to 4.39s of the 5085.53s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ag\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:1623: FutureWarning: \n",
      "The format of the columns of the 'remainder' transformer in ColumnTransformer.transformers_ will change in version 1.7 to match the format of the other transformers.\n",
      "At the moment the remainder columns are stored as indices (of type int). With the same ColumnTransformer configuration, in the future they will be stored as column names (of type str).\n",
      "To use the new behavior now and suppress this warning, use ColumnTransformer(force_int_remainder_cols=False).\n",
      "\n",
      "  warnings.warn(\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_BAG_L3.\n",
      "Fitting model: WeightedEnsemble_L4 ... Training model for up to 406.35s of the 5039.13s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L3': 1.0}\n",
      "\t0.5462\t = Validation score   (accuracy)\n",
      "\t0.53s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L4 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L4 ... Training model for up to 3358.2s of the 5038.12s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "\t0.4852\t = Validation score   (accuracy)\n",
      "\t149.26s\t = Training   runtime\n",
      "\t0.83s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L4 ... Training model for up to 3205.1s of the 4885.01s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.532\t = Validation score   (accuracy)\n",
      "\t527.64s\t = Training   runtime\n",
      "\t0.92s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L4 ... Training model for up to 2672.61s of the 4352.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.5251\t = Validation score   (accuracy)\n",
      "\t889.59s\t = Training   runtime\n",
      "\t0.96s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L4 ... Training model for up to 1777.81s of the 3457.64s of remaining time.\n",
      "\t0.5196\t = Validation score   (accuracy)\n",
      "\t4.9s\t = Training   runtime\n",
      "\t18.92s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L4 ... Training model for up to 1752.09s of the 3431.98s of remaining time.\n",
      "\t0.5057\t = Validation score   (accuracy)\n",
      "\t5.19s\t = Training   runtime\n",
      "\t18.89s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L4 ... Training model for up to 1726.17s of the 3406.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tMany features detected (4290), dynamically setting 'colsample_bylevel' to 0.2331002331002331 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 369.\n",
      "\tMany features detected (4291), dynamically setting 'colsample_bylevel' to 0.23304591004427871 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 371.\n",
      "\tMany features detected (4290), dynamically setting 'colsample_bylevel' to 0.2331002331002331 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 390.\n",
      "\tMany features detected (4290), dynamically setting 'colsample_bylevel' to 0.2331002331002331 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 410.\n",
      "\tMany features detected (4289), dynamically setting 'colsample_bylevel' to 0.23315458148752624 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 430.\n",
      "\tMany features detected (4290), dynamically setting 'colsample_bylevel' to 0.2331002331002331 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 457.\n",
      "\tMany features detected (4290), dynamically setting 'colsample_bylevel' to 0.2331002331002331 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 497.\n",
      "\tMany features detected (4288), dynamically setting 'colsample_bylevel' to 0.2332089552238806 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 618.\n",
      "\t0.5346\t = Validation score   (accuracy)\n",
      "\t1654.46s\t = Training   runtime\n",
      "\t1.15s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L4 ... Training model for up to 67.73s of the 1747.64s of remaining time.\n",
      "\t0.5239\t = Validation score   (accuracy)\n",
      "\t5.61s\t = Training   runtime\n",
      "\t18.55s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L4 ... Training model for up to 41.67s of the 1721.58s of remaining time.\n",
      "\t0.518\t = Validation score   (accuracy)\n",
      "\t4.93s\t = Training   runtime\n",
      "\t18.71s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L4 ... Training model for up to 16.18s of the 1696.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping XGBoost_BAG_L4.\n",
      "Fitting model: NeuralNetTorch_BAG_L4 ... Training model for up to 10.8s of the 1690.69s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\ag\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:1623: FutureWarning: \n",
      "The format of the columns of the 'remainder' transformer in ColumnTransformer.transformers_ will change in version 1.7 to match the format of the other transformers.\n",
      "At the moment the remainder columns are stored as indices (of type int). With the same ColumnTransformer configuration, in the future they will be stored as column names (of type str).\n",
      "To use the new behavior now and suppress this warning, use ColumnTransformer(force_int_remainder_cols=False).\n",
      "\n",
      "  warnings.warn(\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_BAG_L4.\n",
      "Fitting model: LightGBMLarge_BAG_L4 ... Training model for up to 0.38s of the 1680.26s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping LightGBMLarge_BAG_L4.\n",
      "Fitting model: WeightedEnsemble_L5 ... Training model for up to 360.0s of the 1641.01s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L4': 1.0}\n",
      "\t0.5346\t = Validation score   (accuracy)\n",
      "\t0.44s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L5 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L5 ... Training model for up to 1640.55s of the 1640.12s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "\t0.4738\t = Validation score   (accuracy)\n",
      "\t145.03s\t = Training   runtime\n",
      "\t0.85s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L5 ... Training model for up to 1491.65s of the 1491.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.526\t = Validation score   (accuracy)\n",
      "\t495.35s\t = Training   runtime\n",
      "\t1.03s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L5 ... Training model for up to 991.01s of the 990.52s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 585. Best iteration is:\n",
      "\t[332]\tvalid_set's multi_error: 0.469677\n",
      "\t0.5156\t = Validation score   (accuracy)\n",
      "\t815.99s\t = Training   runtime\n",
      "\t0.97s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L5 ... Training model for up to 170.0s of the 169.37s of remaining time.\n",
      "\t0.5141\t = Validation score   (accuracy)\n",
      "\t4.81s\t = Training   runtime\n",
      "\t31.54s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L5 ... Training model for up to 130.99s of the 130.37s of remaining time.\n",
      "\t0.508\t = Validation score   (accuracy)\n",
      "\t5.45s\t = Training   runtime\n",
      "\t29.7s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L5 ... Training model for up to 93.38s of the 92.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tMany features detected (4265), dynamically setting 'colsample_bylevel' to 0.23446658851113716 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 26.\n",
      "\tMany features detected (4262), dynamically setting 'colsample_bylevel' to 0.2346316283435007 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 16.\n",
      "\tMany features detected (4264), dynamically setting 'colsample_bylevel' to 0.23452157598499063 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 17.\n",
      "\tMany features detected (4259), dynamically setting 'colsample_bylevel' to 0.23479690068091102 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 17.\n",
      "\tMany features detected (4264), dynamically setting 'colsample_bylevel' to 0.23452157598499063 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 18.\n",
      "\tMany features detected (4265), dynamically setting 'colsample_bylevel' to 0.23446658851113716 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 18.\n",
      "\tMany features detected (4264), dynamically setting 'colsample_bylevel' to 0.23452157598499063 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 20.\n",
      "\tMany features detected (4263), dynamically setting 'colsample_bylevel' to 0.23457658925639222 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\tRan out of time, early stopping on iteration 23.\n",
      "\t0.4588\t = Validation score   (accuracy)\n",
      "\t88.7s\t = Training   runtime\n",
      "\t1.73s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L6 ... Training model for up to 360.0s of the -53.66s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L3': 1.0}\n",
      "\t0.5462\t = Validation score   (accuracy)\n",
      "\t2.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 18891.18s ... Best model: WeightedEnsemble_L4 | Estimated inference throughput: 19.1 rows/s (776 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20241009_172807\")\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "train_data = TabularDataset(X)\n",
    "# test_data = TabularDataset(test)\n",
    "time_limit = 3600*7\n",
    "predictor = TabularPredictor(label='SUBCLASS').fit(train_data=train_data,presets='best_quality',num_stack_levels=4,time_limit=time_limit,num_gpus=0)\n",
    "# predictions = predictor.predict(test_data)\n",
    "# 361 min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 전처리가 끝난 상태로 저장됐기 때문에 바로 Inference 가능\n",
    "test = test.drop(columns=['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AK2         29\n",
      "ATP6V1H      1\n",
      "CCRL2        2\n",
      "CFP          1\n",
      "CNOT2       77\n",
      "CRAT         1\n",
      "DPYSL4       1\n",
      "GUK1         1\n",
      "IER3         1\n",
      "INHBB        1\n",
      "KCNH1        1\n",
      "MYL1        21\n",
      "NDUFV1       1\n",
      "NUDT4        1\n",
      "POLD2        1\n",
      "PTCH1        1\n",
      "PTGES3       3\n",
      "RBM5        19\n",
      "SCAMP1       1\n",
      "SCNN1A       1\n",
      "SLC25A28     1\n",
      "SYBU         1\n",
      "TMEM97       4\n",
      "TNFAIP6     65\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = test.isna().sum()\n",
    "columns_with_missing_values = missing_values[missing_values > 0]\n",
    "print(columns_with_missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filled = test.fillna(0)\n",
    "# scaler = MinMaxScaler()\n",
    "# test_filled_scaled = scaler.fit_transform(test_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_4304\\379197073.py:2: DeprecationWarning: `get_model_best` has been deprecated and will be removed in version 1.2. Please use `model_best` instead. This will raise an error in the future!\n",
      "  model_to_use = predictor.get_model_best()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      model  score_val eval_metric  pred_time_val  \\\n",
      "0           CatBoost_BAG_L3   0.546202    accuracy     175.990624   \n",
      "1       WeightedEnsemble_L4   0.546202    accuracy     175.991625   \n",
      "2       WeightedEnsemble_L6   0.546202    accuracy     175.992780   \n",
      "3       WeightedEnsemble_L3   0.544751    accuracy     133.058254   \n",
      "4         LightGBMXT_BAG_L2   0.542654    accuracy      93.354912   \n",
      "5           CatBoost_BAG_L2   0.537816    accuracy      93.681303   \n",
      "6         LightGBMXT_BAG_L3   0.536688    accuracy     175.859028   \n",
      "7           LightGBM_BAG_L3   0.536204    accuracy     175.799140   \n",
      "8           CatBoost_BAG_L4   0.534591    accuracy     256.595277   \n",
      "9       WeightedEnsemble_L5   0.534591    accuracy     256.597397   \n",
      "10          LightGBM_BAG_L2   0.533946    accuracy      93.331769   \n",
      "11           XGBoost_BAG_L3   0.533462    accuracy     175.346095   \n",
      "12        LightGBMXT_BAG_L4   0.532011    accuracy     256.369182   \n",
      "13    ExtraTreesGini_BAG_L3   0.528302    accuracy     193.559706   \n",
      "14        LightGBMXT_BAG_L5   0.526044    accuracy     335.406763   \n",
      "15          LightGBM_BAG_L4   0.525077    accuracy     256.413981   \n",
      "16    ExtraTreesGini_BAG_L4   0.523948    accuracy     274.003850   \n",
      "17  RandomForestGini_BAG_L3   0.520722    accuracy     193.452837   \n",
      "18  RandomForestGini_BAG_L4   0.519594    accuracy     274.369979   \n",
      "19    ExtraTreesEntr_BAG_L4   0.517981    accuracy     274.156810   \n",
      "20  RandomForestGini_BAG_L2   0.515562    accuracy     111.760415   \n",
      "21          LightGBM_BAG_L5   0.515562    accuracy     335.350908   \n",
      "22    ExtraTreesEntr_BAG_L3   0.515239    accuracy     193.661889   \n",
      "23  RandomForestGini_BAG_L5   0.514111    accuracy     365.917393   \n",
      "24  RandomForestEntr_BAG_L5   0.507983    accuracy     364.082375   \n",
      "25  RandomForestEntr_BAG_L3   0.506531    accuracy     193.507052   \n",
      "26  RandomForestEntr_BAG_L4   0.505725    accuracy     274.340159   \n",
      "27    ExtraTreesGini_BAG_L2   0.504112    accuracy     111.671418   \n",
      "28  RandomForestEntr_BAG_L2   0.491211    accuracy     111.578029   \n",
      "29    ExtraTreesEntr_BAG_L2   0.488308    accuracy     111.860567   \n",
      "30   NeuralNetFastAI_BAG_L4   0.485244    accuracy     256.277758   \n",
      "31   NeuralNetFastAI_BAG_L3   0.477342    accuracy     175.459076   \n",
      "32   NeuralNetFastAI_BAG_L5   0.473795    accuracy     335.226809   \n",
      "33          CatBoost_BAG_L5   0.458797    accuracy     336.115264   \n",
      "34   NeuralNetFastAI_BAG_L2   0.458313    accuracy      93.077703   \n",
      "35      WeightedEnsemble_L2   0.392679    accuracy      13.172491   \n",
      "36        LightGBMXT_BAG_L1   0.384777    accuracy       0.715726   \n",
      "37          LightGBM_BAG_L1   0.383325    accuracy       0.753689   \n",
      "38          CatBoost_BAG_L1   0.382519    accuracy       1.635166   \n",
      "39           XGBoost_BAG_L1   0.374294    accuracy       0.569291   \n",
      "40     LightGBMLarge_BAG_L1   0.319465    accuracy       1.054736   \n",
      "41    ExtraTreesGini_BAG_L1   0.309466    accuracy      18.139967   \n",
      "42  RandomForestGini_BAG_L1   0.303822    accuracy      18.044421   \n",
      "43    ExtraTreesEntr_BAG_L1   0.292211    accuracy      18.349287   \n",
      "44  RandomForestEntr_BAG_L1   0.290760    accuracy      18.254180   \n",
      "45     CatBoost_r177_BAG_L1   0.257700    accuracy       1.990727   \n",
      "46   NeuralNetFastAI_BAG_L1   0.242864    accuracy       0.723859   \n",
      "47    KNeighborsUnif_BAG_L1   0.225609    accuracy       1.931627   \n",
      "48    KNeighborsDist_BAG_L1   0.217384    accuracy       2.000408   \n",
      "49    NeuralNetTorch_BAG_L1   0.158039    accuracy       8.075183   \n",
      "\n",
      "        fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
      "0   11556.131088                1.342382        2228.860291            3   \n",
      "1   11556.663817                0.001001           0.532729            4   \n",
      "2   11558.221775                0.002156           2.090687            6   \n",
      "3    5799.362949                0.001998           0.450298            3   \n",
      "4    5640.554078                1.116644         754.612913            2   \n",
      "5    7268.170552                1.443035        2382.229387            2   \n",
      "6    9863.812477                1.210786         536.541680            3   \n",
      "7   10146.022820                1.150898         818.752022            3   \n",
      "8   14933.545059                1.145765        1654.456344            4   \n",
      "9   14933.985798                0.002120           0.440739            5   \n",
      "10   6021.589656                1.093501        1135.648491            2   \n",
      "11   9529.424666                0.697853         202.153869            3   \n",
      "12  13806.724340                0.919670         527.635625            4   \n",
      "13   9332.905550               18.911464           5.634752            3   \n",
      "14  17016.017492                1.026349         495.353033            5   \n",
      "15  14168.677933                0.964469         889.589218            4   \n",
      "16  13284.701605               18.554338           5.612890            4   \n",
      "17   9332.069943               18.804595           4.799145            3   \n",
      "18  13283.986960               18.920467           4.898246            4   \n",
      "19  13284.016451               18.707298           4.927737            4   \n",
      "20   4891.072015               19.522148           5.130850            2   \n",
      "21  17336.657289                0.970494         815.992831            5   \n",
      "22   9332.355988               19.013647           5.085191            3   \n",
      "23  16525.475126               31.536979           4.810667            5   \n",
      "24  16526.119396               29.701961           5.454938            5   \n",
      "25   9332.139172               18.858810           4.868374            3   \n",
      "26  13284.282526               18.890647           5.193811            4   \n",
      "27   4891.569211               19.433151           5.628046            2   \n",
      "28   4891.783726               19.339761           5.842561            2   \n",
      "29   4890.793387               19.622299           4.852222            2   \n",
      "30  13428.350588                0.828246         149.261873            4   \n",
      "31   9472.393391                0.810834         145.122594            3   \n",
      "32  16665.691396                0.846394         145.026937            5   \n",
      "33  16609.362030                1.734850          88.697571            5   \n",
      "34   5033.326327                0.839435         147.385162            2   \n",
      "35   3796.419931                0.002000           0.780188            2   \n",
      "36    121.825330                0.715726         121.825330            1   \n",
      "37    148.457337                0.753689         148.457337            1   \n",
      "38   3059.457059                1.635166        3059.457059            1   \n",
      "39    231.456511                0.569291         231.456511            1   \n",
      "40    636.270834                1.054736         636.270834            1   \n",
      "41     23.642939               18.139967          23.642939            1   \n",
      "42     20.032125               18.044421          20.032125            1   \n",
      "43     20.751250               18.349287          20.751250            1   \n",
      "44     17.628466               18.254180          17.628466            1   \n",
      "45     77.331337                1.990727          77.331337            1   \n",
      "46    138.536901                0.723859         138.536901            1   \n",
      "47      0.989301                1.931627           0.989301            1   \n",
      "48      0.993094                2.000408           0.993094            1   \n",
      "49    388.568679                8.075183         388.568679            1   \n",
      "\n",
      "    can_infer  fit_order  \n",
      "0        True         30  \n",
      "1        True         34  \n",
      "2        True         50  \n",
      "3        True         24  \n",
      "4        True         17  \n",
      "5        True         21  \n",
      "6        True         26  \n",
      "7        True         27  \n",
      "8        True         40  \n",
      "9        True         43  \n",
      "10       True         18  \n",
      "11       True         33  \n",
      "12       True         36  \n",
      "13       True         31  \n",
      "14       True         45  \n",
      "15       True         37  \n",
      "16       True         41  \n",
      "17       True         28  \n",
      "18       True         38  \n",
      "19       True         42  \n",
      "20       True         19  \n",
      "21       True         46  \n",
      "22       True         32  \n",
      "23       True         47  \n",
      "24       True         48  \n",
      "25       True         29  \n",
      "26       True         39  \n",
      "27       True         22  \n",
      "28       True         20  \n",
      "29       True         23  \n",
      "30       True         35  \n",
      "31       True         25  \n",
      "32       True         44  \n",
      "33       True         49  \n",
      "34       True         16  \n",
      "35       True         15  \n",
      "36       True          4  \n",
      "37       True          5  \n",
      "38       True          8  \n",
      "39       True         11  \n",
      "40       True         13  \n",
      "41       True          9  \n",
      "42       True          6  \n",
      "43       True         10  \n",
      "44       True          7  \n",
      "45       True         14  \n",
      "46       True          3  \n",
      "47       True          1  \n",
      "48       True          2  \n",
      "49       True         12  \n"
     ]
    }
   ],
   "source": [
    "print(predictor.leaderboard(silent = True))\n",
    "model_to_use = predictor.get_model_best()\n",
    "predictions = predictor.predict(test_filled, model=model_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_labels = le_subclass.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "submisson = pd.read_csv(\"./sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submisson[\"SUBCLASS\"] = original_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submisson.to_csv('amino3_aml4.csv', encoding='UTF-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
