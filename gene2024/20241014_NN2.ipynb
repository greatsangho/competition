{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 17:11:32.397741: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-14 17:11:32.600667: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-14 17:11:34.113214: I tensorflow/c/logging.cc:34] Successfully opened dynamic library libdirectml.d6f03b303ac3c4f2eeb8ca631688c9757b361310.so\n",
      "2024-10-14 17:11:34.113322: I tensorflow/c/logging.cc:34] Successfully opened dynamic library libdxcore.so\n",
      "2024-10-14 17:11:34.120380: I tensorflow/c/logging.cc:34] Successfully opened dynamic library libd3d12.so\n",
      "2024-10-14 17:11:34.277799: I tensorflow/c/logging.cc:34] DirectML device enumeration: found 1 compatible adapters.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# windows\n",
    "test_img = pd.read_pickle(r'./mutation_images/test_imgs_v1.pkl')\n",
    "train_img = pd.read_pickle(r'./mutation_images/train_imgs_v1.pkl')\n",
    "# wsl\n",
    "# test_img = pd.read_pickle(r'/mnt/c/Github/competition/gene2024/mutation_images/test_imgs_v1.pkl')\n",
    "# train_img = pd.read_pickle(r'/mnt/c/Github/competition/gene2024/mutation_images/train_imgs_v1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_dict = pd.read_pickle(r'.\\mutation_images\\subclass_img_dict_v1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6201, 195, 195)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_train = np.array(train_img)\n",
    "np_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두번째부터 여기부터 실행하기 train,test 는 전처리가 끝났음, 바로 모델에 학습시키면 됨\n",
    "import pandas as pd\n",
    "train = pd.read_csv('./open/train_preprocessed.csv')\n",
    "train = train.iloc[:,1:]\n",
    "test = pd.read_csv('./open/test_preprocessed.csv')\n",
    "test = test.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_subclass = LabelEncoder()\n",
    "train['SUBCLASS'] = le_subclass.fit_transform(train['SUBCLASS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 준비\n",
    "X = train.drop(columns=['ID','SUBCLASS'])\n",
    "y = train['SUBCLASS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 데이터 전처리\n",
    "x_train_val,x_test,y_train_val,y_test = train_test_split(np_train,y,random_state=42,test_size=0.2,stratify=y)\n",
    "x_train,x_val,y_train,y_val = train_test_split(x_train_val,y_train_val,random_state=42,test_size=0.2,stratify=y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3968, 195, 195), (992, 195, 195), (1241, 195, 195))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_val.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3968, 195, 195, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import numpy as np\n",
    "def reshape4d(array_in):\n",
    "    # 데이터프레임의 행 개수 구하기\n",
    "    # (3968, 195, 195,1) 배열로 변환\n",
    "    num_rows = array_in.shape[0]\n",
    "    return np.array(array_in.reshape(num_rows, 195, 195, 1))\n",
    "\n",
    "# print(\"변환된 배열의 형태:\", reshaped_array.shape)\n",
    "np_4d_train = reshape4d(x_train)\n",
    "np_4d_val = reshape4d(x_val)\n",
    "np_4d_test = reshape4d(x_test)\n",
    "np_4d_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 191, 191, 64)      1664      \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 191, 191, 64)      0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 187, 187, 64)      102464    \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 187, 187, 64)      0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 93, 93, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 91, 91, 128)       73856     \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 91, 91, 128)       0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 87, 87, 128)       409728    \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 87, 87, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 43, 43, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 236672)            0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               30294144  \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 26)                1690      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,891,802\n",
      "Trainable params: 30,891,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 17:12:34.679645: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - ETA: 0s - loss: 2.7941 - accuracy: 0.2369 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 17:19:15.722939: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-10-14 17:19:15.752754: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-10-14 17:19:15.752948: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14506 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n",
      "2024-10-14 17:19:15.770316: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-10-14 17:19:15.770379: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14506 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n",
      "2024-10-14 17:19:15.772294: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-10-14 17:19:15.772346: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14506 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 417s 13s/step - loss: 2.7941 - accuracy: 0.2369 - val_loss: 2.2248 - val_accuracy: 0.3317\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 401s 13s/step - loss: 1.7824 - accuracy: 0.4612 - val_loss: 2.1714 - val_accuracy: 0.3327\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 403s 13s/step - loss: 1.0349 - accuracy: 0.6830 - val_loss: 2.6714 - val_accuracy: 0.2974\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 404s 13s/step - loss: 0.7151 - accuracy: 0.7752 - val_loss: 2.8074 - val_accuracy: 0.3034\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 404s 13s/step - loss: 0.5554 - accuracy: 0.8259 - val_loss: 3.9379 - val_accuracy: 0.2853\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 403s 13s/step - loss: 0.4245 - accuracy: 0.8546 - val_loss: 5.8778 - val_accuracy: 0.2903\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 396s 13s/step - loss: 0.3655 - accuracy: 0.8745 - val_loss: 3.2607 - val_accuracy: 0.2893\n",
      "39/39 [==============================] - 23s 510ms/step - loss: 3.4417 - accuracy: 0.2917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 18:00:10.023861: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-10-14 18:00:10.054215: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-10-14 18:00:10.054485: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14506 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n",
      "2024-10-14 18:00:10.056909: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-10-14 18:00:10.057003: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14506 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n",
      "2024-10-14 18:00:10.058349: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-10-14 18:00:10.058410: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14506 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 17s 427ms/step - loss: 3.4417 - accuracy: 0.2917\n",
      "[3.4417216777801514, 0.29170024394989014]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, Activation, MaxPooling2D, Flatten, Dense, AveragePooling2D, AveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "num_classes = len(y.unique())\n",
    "\n",
    "# 모델 정의\n",
    "model = Sequential([\n",
    "    # 입력 데이터 형태는 (65, 65, 1)\n",
    "    Conv2D(64, kernel_size=5, strides=1, input_shape=(195, 195, 1)),\n",
    "    Activation('relu'),\n",
    "    Conv2D(64, kernel_size=5, strides=1),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    # AveragePooling2D(pool_size=2),\n",
    "    \n",
    "    Conv2D(128, kernel_size=3, strides=1),\n",
    "    Activation('relu'),\n",
    "    Conv2D(128, kernel_size=5, strides=1),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    # AveragePooling2D(pool_size=2),\n",
    "    \n",
    "    # Conv2D(256, kernel_size=5, strides=1),\n",
    "    # Activation('relu'),\n",
    "    # Conv2D(256, kernel_size=5, strides=1),\n",
    "    # Activation('relu'),\n",
    "    # Conv2D(256, kernel_size=5, strides=1),\n",
    "    # Activation('relu'),\n",
    "    # MaxPooling2D(pool_size=2),\n",
    "    # # AveragePooling2D(pool_size=2),\n",
    "\n",
    "    # Conv2D(256, kernel_size=5, strides=1),\n",
    "    # Activation('relu'),\n",
    "    # Conv2D(256, kernel_size=5, strides=1),\n",
    "    # Activation('relu'),\n",
    "    # Conv2D(256, kernel_size=5, strides=1),\n",
    "    # Activation('relu'),\n",
    "    # MaxPooling2D(pool_size=2),\n",
    "\n",
    "    # 분류 레이어\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam', metrics=['accuracy']) # sparse_categorical_crossentropy\n",
    "\n",
    "# 콜백 정의\n",
    "callbacks = [EarlyStopping(monitor='val_accuracy', patience=5, verbose=0)]\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(np_4d_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=(np_4d_val, y_val))\n",
    "\n",
    "# 모델 평가\n",
    "scores = model.evaluate(np_4d_test, y_test, verbose=1)\n",
    "\n",
    "# 모델 저장\n",
    "model.save('conv_model001.keras')\n",
    "\n",
    "# 모델 불러오기\n",
    "loaded_model = load_model('conv_model001.keras')\n",
    "\n",
    "# 불러온 모델 평가 (확인용)\n",
    "loaded_scores = loaded_model.evaluate(x_test, y_test, verbose=1)\n",
    "print(loaded_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
